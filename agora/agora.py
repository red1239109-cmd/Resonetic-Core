# SPDX-License-Identifier: MIT
# Copyright (C) 2026 red1239109-cmd
# ==============================================================================
# File: agora_final.py
# Project: The Grand Philosophical Agora (Production Ready Edition)
# Version: 27.1 (Zombie Killer+ / Strict State / Clean Restart)
#
# [Patch v27.1]
# - Fix: nonlocal placement (was SyntaxError inside finally block)
# - Fix: update guard also checks simulation_task.done()
# - Upgrade: safe_send triggers stop_event + cancels simulation_task on socket failure
# - Upgrade: start/stop awaits cancelled task to avoid stray sends
# ==============================================================================

from __future__ import annotations
from dataclasses import dataclass, field
from typing import Dict, List, Tuple, Optional, Set, Union
import random, math, re
import asyncio
import json

# --- Server Imports ---
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
import uvicorn

# ============================================================
# [SECTION 1] The Engine
# ============================================================

WINDOW_SIZE = 6
WARMUP_CAST_PASSES = 1
RE_ROLL_THRESHOLD = 0.25
RHETORIC_THRESHOLD = 0.75

def clamp(x: float, lo: float, hi: float) -> float:
    return lo if x < lo else hi if x > hi else x

def softmax(xs: List[float], temp: float = 1.0) -> List[float]:
    if not xs: return []
    m = max(xs)
    exps = [math.exp((x - m) / max(1e-9, temp)) for x in xs]
    z = sum(exps) or 1.0
    return [e / z for e in exps]

def cosine_sim(a: Dict[str, float], b: Dict[str, float]) -> float:
    keys = set(a) | set(b)
    if not keys: return 0.0
    dot = sum(a.get(k, 0.0) * b.get(k, 0.0) for k in keys)
    na = math.sqrt(sum(a.get(k, 0.0) ** 2 for k in keys)) or 1.0
    nb = math.sqrt(sum(b.get(k, 0.0) ** 2 for k in keys)) or 1.0
    return dot / (na * nb)

def jaccard(a: Set[str], b: Set[str]) -> float:
    if not a and not b: return 1.0
    if not a or not b: return 0.0
    return len(a & b) / len(a | b)

def tokenize(text: str) -> Set[str]:
    return set(re.findall(r"[ê°€-í£A-Za-z]{2,}", text))

CONCEPT_SYNONYMS = {
    "ì§„ë¦¬": {"ì§„ë¦¬", "ì°¸", "ì°¸ë¨", "ì‚¬ì‹¤", "ì •ë‹¹í™”", "ì¸ì‹"},
    "ì´ì„±": {"ì´ì„±", "í•©ë¦¬", "ë…¼ë¦¬", "ì¶”ë¡ ", "ì—°ì—­"},
    "ê²½í—˜": {"ê²½í—˜", "ê´€ì°°", "ì‚¬ë¡€", "ì‹¤í—˜"},
    "ë³´í¸": {"ë³´í¸", "í•„ì—°", "ì¼ë°˜", "ê·œë²”"},
    "ë„ë•": {"ë„ë•", "ì˜ë¬´", "ì •ì–¸", "ìœ¤ë¦¬", "ì¡´ì—„", "ì„ "},
    "ììœ ": {"ììœ ", "ììœ¨", "ì˜ì§€"},
    "ê¶Œë ¥": {"ê¶Œë ¥", "í˜", "ì§€ë°°", "ìœ„ê³„"},
    "ê°€ì¹˜": {"ê°€ì¹˜", "í‰ê°€", "ì„ ì•…", "ì˜ë¯¸"},
    "ì–¸ì–´": {"ì–¸ì–´", "ë§", "í‘œí˜„", "ë¬¸ë²•", "ì‚¬ìš©"},
    "ì¡´ì¬": {"ì¡´ì¬", "ì‹¤ì¬", "ì‹¤ì²´", "ì¡´ì¬ë¡ "},
    "í˜•ì´ìƒ": {"í˜•ì´ìƒ", "ì´ˆì›”", "ë³¸ì§ˆ", "ì´ë°ì•„"},
    "ì‚¬íšŒ": {"ì‚¬íšŒ", "ì œë„", "ê·œìœ¨", "ì •ì¹˜", "ê³µì "},
    "ì—­ì‚¬": {"ì—­ì‚¬", "ê³„ë³´", "ì‹œëŒ€", "ë°œì „"},
    "ì£¼ì²´": {"ì£¼ì²´", "ìì•„", "ì˜ì‹"},
    "ë°©ë²•": {"ë°©ë²•", "ë¹„íŒ", "ë¶„ì„", "ë³€ì¦", "í•´ì²´", "ê²€ì—´"},
}

PHILO_GRAPHS = {
    "í”Œë¼í†¤": {"í˜•ì´ìƒ": {"ì§„ë¦¬", "ë³´í¸", "ì¡´ì¬"}, "ì§„ë¦¬": {"í˜•ì´ìƒ", "ë³´í¸", "ì´ì„±"}, "ë³´í¸": {"ì§„ë¦¬", "í˜•ì´ìƒ", "ì´ì„±"}},
    "ì•„ë¦¬ìŠ¤í† í…”ë ˆìŠ¤": {"ê²½í—˜": {"ì§„ë¦¬", "ì¡´ì¬", "ë°©ë²•"}, "ì¡´ì¬": {"ê²½í—˜", "ì§„ë¦¬", "ë°©ë²•"}, "ë°©ë²•": {"ê²½í—˜", "ì¡´ì¬", "ì§„ë¦¬"}},
    "ì¹¸íŠ¸": {"ì´ì„±": {"ë³´í¸", "ë„ë•", "ë°©ë²•"}, "ë³´í¸": {"ì´ì„±", "ë„ë•", "ììœ "}, "ììœ ": {"ë„ë•", "ë³´í¸"}, "ì£¼ì²´": {"ë°©ë²•", "ê²½í—˜"}, "ë°©ë²•": {"ì´ì„±", "ë³´í¸"}},
    "ë‹ˆì²´": {"ê¶Œë ¥": {"ê°€ì¹˜", "ì§„ë¦¬", "ì—­ì‚¬"}, "ê°€ì¹˜": {"ê¶Œë ¥", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ê¶Œë ¥", "ê°€ì¹˜"}, "ì—­ì‚¬": {"ê¶Œë ¥", "ê°€ì¹˜"}},
    "ì†Œí¬ë¼í…ŒìŠ¤": {"ë°©ë²•": {"ì§„ë¦¬", "ì£¼ì²´", "ì´ì„±"}, "ì£¼ì²´": {"ë°©ë²•", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ë°©ë²•", "ì´ì„±"}},
    "ë°ì¹´ë¥´íŠ¸": {"ì£¼ì²´": {"ì´ì„±", "ì§„ë¦¬"}, "ì´ì„±": {"ì£¼ì²´", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì£¼ì²´", "ì´ì„±"}},
    "í„": {"ê²½í—˜": {"ì§„ë¦¬", "ë°©ë²•"}, "ë°©ë²•": {"ê²½í—˜", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ê²½í—˜", "ë°©ë²•"}},
    "ìŠ¤í”¼ë…¸ì": {"ì¡´ì¬": {"ì´ì„±", "ë³´í¸", "ì§„ë¦¬"}, "ì´ì„±": {"ì¡´ì¬", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì¡´ì¬", "ë³´í¸"}},
    "ë¼ì´í”„ë‹ˆì¸ ": {"ì´ì„±": {"ë³´í¸", "ì§„ë¦¬", "í˜•ì´ìƒ"}, "í˜•ì´ìƒ": {"ì´ì„±", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì´ì„±", "ë³´í¸"}},
    "ë¡œí¬": {"ê²½í—˜": {"ì£¼ì²´", "ì§„ë¦¬", "ì‚¬íšŒ"}, "ì£¼ì²´": {"ê²½í—˜", "ì§„ë¦¬"}, "ì‚¬íšŒ": {"ê²½í—˜", "ì§„ë¦¬"}},
    "ë£¨ì†Œ": {"ì‚¬íšŒ": {"ììœ ", "ë„ë•", "ê°€ì¹˜"}, "ììœ ": {"ì‚¬íšŒ", "ë„ë•"}, "ë„ë•": {"ì‚¬íšŒ", "ììœ "}},
    "ë°€": {"ê°€ì¹˜": {"ë„ë•", "ì‚¬íšŒ", "ì§„ë¦¬"}, "ë„ë•": {"ê°€ì¹˜", "ì‚¬íšŒ"}, "ì‚¬íšŒ": {"ê°€ì¹˜", "ë„ë•"}},
    "ë§ˆë¥´í¬ìŠ¤": {"ì‚¬íšŒ": {"ì—­ì‚¬", "ê¶Œë ¥", "ê°€ì¹˜"}, "ì—­ì‚¬": {"ì‚¬íšŒ", "ê¶Œë ¥"}, "ê¶Œë ¥": {"ì‚¬íšŒ", "ì—­ì‚¬"}},
    "í—¤ê²”": {"ì—­ì‚¬": {"ë°©ë²•", "ì§„ë¦¬", "ì‚¬íšŒ"}, "ë°©ë²•": {"ì—­ì‚¬", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì—­ì‚¬", "ë°©ë²•"}},
    "ì‡¼íœí•˜ìš°ì–´": {"ê°€ì¹˜": {"ì¡´ì¬", "ì£¼ì²´"}, "ì£¼ì²´": {"ê°€ì¹˜", "ì¡´ì¬"}, "ì¡´ì¬": {"ì£¼ì²´", "ê°€ì¹˜"}},
    "í‚¤ë¥´ì¼€ê³ ë¥´": {"ì£¼ì²´": {"ê°€ì¹˜", "ë„ë•", "ì§„ë¦¬"}, "ê°€ì¹˜": {"ì£¼ì²´", "ë„ë•"}, "ì§„ë¦¬": {"ì£¼ì²´", "ê°€ì¹˜"}},
    "ë¹„íŠ¸ê²ìŠˆíƒ€ì¸": {"ì–¸ì–´": {"ë°©ë²•", "ì§„ë¦¬"}, "ë°©ë²•": {"ì–¸ì–´", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì–¸ì–´", "ë°©ë²•"}},
    "í•˜ì´ë°ê±°": {"ì¡´ì¬": {"ì£¼ì²´", "ì§„ë¦¬"}, "ì£¼ì²´": {"ì¡´ì¬", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì¡´ì¬", "ì£¼ì²´"}},
    "ì‚¬ë¥´íŠ¸ë¥´": {"ììœ ": {"ì£¼ì²´", "ê°€ì¹˜", "ë„ë•"}, "ì£¼ì²´": {"ììœ ", "ê°€ì¹˜"}, "ê°€ì¹˜": {"ììœ ", "ì£¼ì²´"}},
    "í‘¸ì½”": {"ì‚¬íšŒ": {"ê¶Œë ¥", "ì§„ë¦¬", "ì—­ì‚¬"}, "ê¶Œë ¥": {"ì‚¬íšŒ", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì‚¬íšŒ", "ê¶Œë ¥"}},
    "ì•„ë ŒíŠ¸": {"ì‚¬íšŒ": {"ì§„ë¦¬", "ì—­ì‚¬", "ê°€ì¹˜"}, "ê°€ì¹˜": {"ì‚¬íšŒ", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì‚¬íšŒ", "ê°€ì¹˜"}},
    "í¬í¼": {"ë°©ë²•": {"ê²½í—˜", "ì§„ë¦¬"}, "ê²½í—˜": {"ë°©ë²•", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ë°©ë²•", "ê²½í—˜"}},
    "ë¡¤ìŠ¤": {"ë„ë•": {"ì‚¬íšŒ", "ììœ ", "ë³´í¸"}, "ì‚¬íšŒ": {"ë„ë•", "ë³´í¸"}, "ë³´í¸": {"ë„ë•", "ì‚¬íšŒ"}},
}

def extract_concepts(text: str) -> Set[str]:
    out: Set[str] = set()
    for c, syns in CONCEPT_SYNONYMS.items():
        for s in syns:
            if s in text:
                out.add(c)
                break
    return out

def pick_target_concept_from_other(other_claim: str, fallback: str = "ì§„ë¦¬") -> str:
    cs = list(extract_concepts(other_claim))
    if cs: return random.choice(cs)
    return fallback

def concept_graph_score(philo: str, text: str) -> float:
    cset = extract_concepts(text)
    g = PHILO_GRAPHS.get(philo, {})
    if not cset: return 0.0

    if g:
        nodes = set(g.keys())
        coverage = (len(cset & nodes) / max(1, len(nodes)))
    else:
        coverage = min(1.0, len(cset) / 4)

    pairs = 0
    hits = 0
    cl = list(cset)
    for i in range(len(cl)):
        for j in range(i + 1, len(cl)):
            a, b = cl[i], cl[j]
            pairs += 1
            if g and (b in g.get(a, set()) or a in g.get(b, set())):
                hits += 1
            elif not g:
                hits += 0.5

    coherence = hits / max(1, pairs)
    return clamp(0.55 * coverage + 0.45 * coherence, 0.0, 1.0)

@dataclass(frozen=True)
class InferenceTaboo:
    name: str
    pattern: re.Pattern
    penalty: float
    explanation: str
    repair_hint: str

def taboo_score(taboo_rules: Union[List[InferenceTaboo], InferenceTaboo, None], text: str) -> Tuple[float, List[InferenceTaboo]]:
    if taboo_rules is None: taboo_rules = []
    if isinstance(taboo_rules, InferenceTaboo): taboo_rules = [taboo_rules]
    s = 0.0
    hits: List[InferenceTaboo] = []
    for r in taboo_rules:
        if r.pattern.search(text):
            s += r.penalty
            hits.append(r)
    return clamp(s, 0.0, 1.0), hits

TABOOS = {
    "kant_empirical_jump": InferenceTaboo("ê²½í—˜â†’ë³´í¸ ì í”„", re.compile(r"(ê²½í—˜|ê´€ì°°|ì‚¬ë¡€).*(ê·¸ë˜ì„œ|ë”°ë¼ì„œ).*(ë³´í¸|í•„ì—°|ê·œë²”|ì˜ë¬´)", re.UNICODE), 0.65, "ê²½í—˜ ë„ì•½", "ê²½í—˜ ëŒ€ì‹  'ê°€ëŠ¥ì¡°ê±´'ì„ ìš”êµ¬í•˜ë¼."),
    "kant_ends_justify": InferenceTaboo("ëª©ì ì´ ìˆ˜ë‹¨ ì •ë‹¹í™”", re.compile(r"(ëª©ì |ê²°ê³¼).*(ìˆ˜ë‹¨).*(ì •ë‹¹í™”|í•©ë¦¬í™”)", re.UNICODE), 0.75, "ì¡´ì—„ ì¶©ëŒ", "ìˆ˜ë‹¨-ëª©ì  ë…¼ì¦ì„ ì¤‘ë‹¨í•˜ê³  'ì¡´ì—„' ì œì•½ì„ ì‚½ì…í•˜ë¼."),
    "nietzsche_universal_morals": InferenceTaboo("ë³´í¸ ë„ë• ë‹¨ì–¸", re.compile(r"(ë³´í¸|ì ˆëŒ€).*(ë„ë•|ìœ¤ë¦¬|ì„ |ì•…|ë²•ì¹™)", re.UNICODE), 0.70, "ë³´í¸ ë„ë• ì˜ì‹¬", "'ëˆ„ê°€ ì´ë“ì„ ë³´ëŠ”ê°€'ë¡œ ê³„ë³´í•™ì  ì „í™˜ì„ ìˆ˜í–‰í•˜ë¼."),
    "nietzsche_truth_worship": InferenceTaboo("ì§„ë¦¬ ìˆ­ë°°", re.compile(r"(ì§„ë¦¬).*(ìµœê³ |ì‹ ì„±|ì ˆëŒ€|ìˆ­ë°°)", re.UNICODE), 0.55, "ì§„ë¦¬ ê°€ì¹˜ ì‹¬ë¬¸", "'ì§„ë¦¬ê°€ ì™œ ì„ ì¸ê°€'ë¥¼ ë¬»ëŠ” ê°€ì¹˜ì „ë„ ì§ˆë¬¸ì„ ì‚½ì…í•˜ë¼."),
    "hume_necessary_causation": InferenceTaboo("í•„ì—° ì¸ê³¼ ë‹¨ì–¸", re.compile(r"(ì›ì¸|ì¸ê³¼).*(ë°˜ë“œì‹œ|í•„ì—°|ì ˆëŒ€)", re.UNICODE), 0.65, "í•„ì—°ì„± íšŒì˜", "'ìŠµê´€/ê¸°ëŒ€'ë¡œ ì„¤ëª…ì„ í™˜ì›í•˜ë¼."),
    "witt_metaphysics_assert": InferenceTaboo("í˜•ì´ìƒí•™ ë‹¨ì–¸", re.compile(r"(ì´ë°ì•„|ì´ˆì›”|ë³¸ì§ˆ).*(ì¡´ì¬í•œë‹¤|ì‹¤ì¬í•œë‹¤|í™•ì‹¤í•˜ë‹¤)", re.UNICODE), 0.70, "ì–¸ì–´ í•œê³„ ì´ˆê³¼", "'ì–¸ì–´ ì‚¬ìš© ê·œì¹™'ìœ¼ë¡œ ì „í™˜í•˜ë¼."),
    "foucault_truth_neutral": InferenceTaboo("ì§„ë¦¬ ì¤‘ë¦½ì„±", re.compile(r"(ì§„ë¦¬).*(ì¤‘ë¦½|ìˆœìˆ˜|ë¬´ê´€)", re.UNICODE), 0.70, "ê¶Œë ¥-ì§€ì‹ ë§ê°", "'ì œë„/ê·œìœ¨/ì •ìƒí™”'ë¥¼ ë„£ì–´ ê¶Œë ¥ í”„ë ˆì„ìœ¼ë¡œ ì „í™˜í•˜ë¼."),
}

@dataclass
class Lexicon:
    core: List[str]
    evidentials: List[str]
    hedges: List[str]
    intensifiers: List[str]
    metaphors: List[str]
    taboo_softeners: List[str]

@dataclass
class ReasoningOps:
    ops: List[str]

@dataclass
class StyleProfile:
    rhetoric_bias: float
    justification_bias: float
    interrogation_bias: float
    poetic_bias: float

@dataclass
class Philosopher:
    name: str
    era: str
    truth_vector: Dict[str, float]
    lexicon: Lexicon
    reasoning: ReasoningOps
    taboo: List[InferenceTaboo]
    style: StyleProfile
    phase: Dict[str, float] = field(default_factory=lambda: {"open": 0.5, "attack": 0.5, "synthesize": 0.5})

@dataclass
class ArgGraph:
    claim: str = ""
    warrant: str = ""
    attack: str = ""
    constraint: str = ""
    synthesis: str = ""

def pick(xs: List[str]) -> str:
    return random.choice(xs) if xs else ""

def tension_to_register(t: float) -> str:
    return "low" if t < 0.33 else "mid" if t < 0.66 else "high"

# --- Ops ---
def op_define_split(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    w = pick(p.lexicon.evidentials) or "ìš°ì„ "
    g.claim = f"{w} '{tgt}'ë¥¼ ë§í•  ë•Œ, ìš°ë¦¬ëŠ” 'ì‚¬ì‹¤'ê³¼ 'ì •ë‹¹í™”'ë¥¼ ì„ì–´ ë§í•©ë‹ˆë‹¤."
    g.warrant = "ì •ì˜ê°€ íë¦¬ë©´ ë…¼ìŸì€ ë§ì˜ ë¯¸ë„ëŸ¬ì§ì´ ë©ë‹ˆë‹¤."

def op_condition_censor(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¥¼ íŒë‹¨í•œë‹¤ëŠ” ë§ ìì²´ê°€ ì„±ë¦½í•˜ë ¤ë©´, ë¬´ì—‡ì´ ê·¸ê²ƒì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆê¹Œ?"
    g.warrant = "ê²½í—˜ë§Œìœ¼ë¡œëŠ” ë³´í¸ íƒ€ë‹¹ì„±ì„ ë³´ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    g.constraint = "ë”°ë¼ì„œ ê°€ëŠ¥í•œ ì¡°ê±´ì„ ë¨¼ì € ì„¸ì›Œì•¼ í•©ë‹ˆë‹¤."

def op_empirical_classify(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¼ê³  ë¶ˆë¦¬ëŠ” ì‚¬ë¡€ë“¤ì„ ëª¨ì•„ë´…ì‹œë‹¤: ê³¼í•™ì˜ ê²€ì¦, ë²•ì •ì˜ ì¦ëª…, ì¼ìƒì˜ ì‹ ë¢°."
    g.warrant = "ì‘ë™ ë°©ì‹ì´ ë‹¤ë¥¸ ê²ƒë“¤ì„ í•˜ë‚˜ë¡œ ë­‰ì¹˜ë©´ ì„¤ëª…ì´ ë¬´ë„ˆì§‘ë‹ˆë‹¤."
    g.constraint = "ë¶„ë¥˜ì™€ ì›ì¸ ë¶„ì„ì´ ë¨¼ì €ì…ë‹ˆë‹¤."

def op_reductio(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.attack = f"ì¢‹ìŠµë‹ˆë‹¤. ë§Œì•½ '{tgt}'ê°€ ì ˆëŒ€ì ì´ë¼ ê°€ì •í•©ì‹œë‹¤. ê·¸ëŸ¬ë©´ ì°¸ê³¼ ê±°ì§“ì˜ êµ¬ë¶„ ìì²´ê°€ ë¶•ê´´í•©ë‹ˆë‹¤."
    g.warrant = "êµ¬ë¶„ì´ ë¶•ê´´í•˜ë©´ ì£¼ì¥ë„ ìŠ¤ìŠ¤ë¡œì˜ ë°œíŒì„ ìƒìŠµë‹ˆë‹¤."

def op_genealogy_expose(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = random.choice([
        f"'{tgt}'ëŠ” ìˆœìˆ˜í•œ ì–¼êµ´ì„ í•˜ê³  ë“±ì¥í•˜ì§€ë§Œ, ì—­ì‚¬ì ìœ¼ë¡œëŠ” ëˆ„êµ°ê°€ì˜ ì†ì— ë“¤ë¦° ë„êµ¬ì˜€ë‹¤.",
        f"'{tgt}'ë¼ëŠ” ë§ì´ ë“±ì¥í•˜ëŠ” ìˆœê°„, ì´ë¯¸ ëˆ„êµ°ê°€ì˜ ê¸°ì¤€ì´ ìŠ¹ë¦¬í•œ ê²ƒì´ë‹¤.",
        f"'{tgt}'ë¥¼ ë§í•˜ëŠ” ë°©ì‹ ìì²´ê°€ í˜ì˜ ë°°ì¹˜ë¥¼ ë“œëŸ¬ë‚¸ë‹¤.",
    ])
    g.attack = random.choice([
        "ëˆ„ê°€ ê·¸ê²ƒì„ ë§í•  ê¶Œë¦¬ë¥¼ ë…ì í–ˆëŠ”ê°€?",
        "ê·¸ ë§ì´ ë¬´ì—‡ì„ ì •ìƒìœ¼ë¡œ ë§Œë“¤ê³  ë¬´ì—‡ì„ ë¹„ì •ìƒìœ¼ë¡œ ë°€ì–´ëƒˆëŠ”ê°€?",
        "ê·¸ ë‹´ë¡ ì´ ëˆ„êµ¬ë¥¼ â€˜ê°•ìâ€™ë¡œ, ëˆ„êµ¬ë¥¼ â€˜ì•½ìâ€™ë¡œ ë°°ì¹˜í–ˆëŠ”ê°€?",
    ])
    g.warrant = "ê³„ë³´ë¥¼ ë”°ë¼ê°€ë©´, â€˜ì°¸â€™ì€ ì¢…ì¢… ê°€ì¹˜ì™€ ê¶Œë ¥ì˜ ëƒ„ìƒˆë¥¼ í’ê¸´ë‹¤."

def op_value_invert(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = random.choice([
        f"ì™œ '{tgt}'ê°€ ì„ ì´ë¼ëŠ” ì „ì œê°€ ìë™ìœ¼ë¡œ í†µê³¼í•˜ëŠ”ê°€?",
        f"'{tgt}'ë¥¼ ìˆ­ë°°í•˜ëŠ” ìë“¤ì€ ëŒ€ì²´ ë¬´ì—‡ì„ ë‘ë ¤ì›Œí•˜ëŠ”ê°€?",
        f"'{tgt}'ê°€ ì‚¶ì„ ê°•í™”í•œë‹¤ëŠ” ì¦ê±°ê°€ ìˆëŠ”ê°€â€”ì•„ë‹ˆë©´ ì‚¶ì„ ë§ˆë¹„ì‹œí‚¤ëŠ”ê°€?",
    ])
    g.warrant = "ê°€ì¹˜ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ë’¤ì§‘ì–´ ì ê²€í•˜ì§€ ì•Šìœ¼ë©´, â€˜ì§„ë¦¬â€™ëŠ” ìš°ìƒì´ ëœë‹¤."
    g.attack = "ë‚˜ëŠ” ìš°ìƒì„ ë¶€ìˆ˜ëŠ” ìª½ì„ íƒí•œë‹¤."

def op_language_therapy(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"ì—¬ê¸°ì„œ í˜¼ë€ì€ '{tgt}'ë¼ëŠ” ë‹¨ì–´ì˜ ì‚¬ìš© ê·œì¹™ì—ì„œ ë¹„ë¡¯ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    g.warrant = "ë§ì˜ ì“°ì„ì„ ì •ë¦¬í•˜ë©´, ë¬¸ì œì˜ ì ˆë°˜ì€ ì‚¬ë¼ì§‘ë‹ˆë‹¤."
    g.constraint = "í˜•ì´ìƒí•™ì  ë‹¨ì–¸ ëŒ€ì‹  ì‚¬ìš© ê·œì¹™ì„ ë³´ì„¸ìš”."

def op_power_knowledge(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = "ì§„ë¦¬ëŠ” ì§€ì‹ì˜ í˜•íƒœë¥¼ ë ì§€ë§Œ, ì§€ì‹ì€ ì œë„ì™€ ê·œìœ¨ê³¼ ì—°ê²°ë©ë‹ˆë‹¤."
    g.attack = f"'{tgt}' ë‹´ë¡ ì´ ë¬´ì—‡ì„ ì •ìƒí™”í•˜ê³  ë¬´ì—‡ì„ ë°°ì œí•˜ëŠ”ì§€ ë³´ì§€ ì•Šìœ¼ë©´ í•µì‹¬ì„ ë†“ì¹©ë‹ˆë‹¤."
    g.warrant = "ê¶Œë ¥-ì§€ì‹ ì¥ì¹˜ê°€ 'ì°¸'ì˜ ì¡°ê±´ì„ ë§Œë“­ë‹ˆë‹¤."

def op_public_world(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ëŠ” ê°œì¸ ë¨¸ë¦¿ì†ì—ë§Œ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ê³µì  ì„¸ê³„ì—ì„œ ë§ê³¼ í–‰ìœ„ë¡œ ë“œëŸ¬ë‚©ë‹ˆë‹¤."
    g.warrant = "ì§„ë¦¬ëŠ” ì„¸ê³„-ê³µìœ ì™€ ì±…ì„ì˜ ë¬¸ì œì…ë‹ˆë‹¤."
    g.synthesis = "ê·¸ë˜ì„œ ì§„ë¦¬ ë…¼ìŸì€ ì •ì¹˜ì Â·ìœ¤ë¦¬ì  ì°¨ì›ì„ í”¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def op_elenchus(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¥¼ ì•ˆë‹¤ê³  ë§í•˜ëŠ”êµ°. ê·¸ë ‡ë‹¤ë©´ '{tgt}'ë¥¼ ì´ë£¨ëŠ” ìµœì†Œ ì¡°ê±´ í•˜ë‚˜ë§Œ ë§í•´ë³´ê²Œ."
    g.attack = "ê·¸ ì¡°ê±´ì´ í”ë“¤ë¦¬ë©´, ë„ˆì˜ 'ì•ˆë‹¤'ëŠ” ë§ë„ ê°™ì´ í”ë“¤ë¦°ë‹¤."
    g.warrant = "ì •ì˜ ì—†ì´ í™•ì‹ ë§Œ ë‚¨ìœ¼ë©´, ìš°ë¦¬ëŠ” ë§ì— ì†ëŠ”ë‹¤."

def op_methodic_doubt(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"ë‚˜ëŠ” '{tgt}'ì— ëŒ€í•´, ì˜ì‹¬ ê°€ëŠ¥í•œ ê²ƒì€ ì „ë¶€ ì˜ì‹¬í•´ë³´ê² ë‹¤."
    g.warrant = "ì˜ì‹¬ì„ í†µê³¼í•œ ê²ƒë§Œì´ í™•ì‹¤ì„±ì˜ ìê²©ì„ ì–»ëŠ”ë‹¤."
    g.constraint = "ê·¸ëŸ¬ë‹ˆ ë¨¼ì € ì˜ì‹¬ì— ê²¬ë””ëŠ” í† ëŒ€ë¥¼ ì œì‹œí•˜ë¼."

def op_hume_skeptic(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¥¼ ë§í•  ë•Œ, ìš°ë¦¬ëŠ” ë°˜ë³µì—ì„œ ìƒê¸´ ê¸°ëŒ€ë¥¼ 'í•„ì—°'ìœ¼ë¡œ ì°©ê°í•˜ê³¤ í•œë‹¤."
    g.warrant = "ì¸ê³¼Â·í•„ì—°Â·í™•ì‹¤ì€ ì¢…ì¢… ìŠµê´€ì˜ ë‹¤ë¥¸ ì´ë¦„ì´ë‹¤."
    g.attack = "ë„ˆì˜ í™•ì‹ ì€ ê²½í—˜ì˜ ë¹ˆí‹ˆì„ ë©”ìš°ëŠ” ìƒìƒì¼ ìˆ˜ ìˆë‹¤."

def op_dialectic(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ëŠ” ê³ ì •ëœ ì ì´ ì•„ë‹ˆë¼, ì¶©ëŒ ì†ì—ì„œ ì „ê°œë˜ëŠ” ê³¼ì •ì´ë‹¤."
    g.warrant = "í•œìª½ë§Œ ë¶™ë“¤ë©´ ëª¨ìˆœì´ ìŒ“ì´ê³ , ê·¸ ëª¨ìˆœì´ ë‹¤ìŒ êµ­ë©´ì„ ì—°ë‹¤."
    g.synthesis = "ê·¸ëŸ¬ë‹ˆ ë°˜ëŒ€í•­ì„ ì œê±°í•˜ì§€ ë§ê³ , ë” ë†’ì€ í†µì¼ë¡œ ë“¤ì–´ì˜¬ë ¤ë¼."

def op_pessimism_will(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ëŠ” ì´ì„±ì˜ ìŠ¹ë¦¬ê°€ ì•„ë‹ˆë¼, ì˜ì§€ê°€ ìê¸° ê³ í†µì„ í¬ì¥í•˜ëŠ” ë°©ì‹ì¼ ìˆ˜ ìˆë‹¤."
    g.warrant = "ì‚¶ì´ ë¨¼ì €ì´ê³ , ì´ì„±ì€ ê·¸ ë’¤ë¥¼ ë”°ë¼ ë¯¸í™”í•œë‹¤."
    g.attack = "ë„ˆì˜ ì§„ë¦¬ëŠ” ê³ í†µì„ ëœì–´ì£¼ëŠ” ì•½ì¸ê°€, í˜„ì‹¤ì„ ê°€ë¦¬ëŠ” ì•ˆê°œì¸ê°€?"

def op_subjective_truth(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ê°€ ê°ê´€ì  ê³µë¬¸ì„œì²˜ëŸ¼ ì¡´ì¬í•œë‹¤ëŠ” ë¯¿ìŒë¶€í„° ì˜ì‹¬í•˜ì."
    g.warrant = "ì¤‘ìš”í•œ ê²ƒì€ ë‚´ê°€ ê·¸ ì§„ë¦¬ì— ì–´ë–»ê²Œ â€˜ê±¸ë ¤ë“œëŠ”ê°€â€™ë‹¤."
    g.attack = "ë„ˆì˜ ì§„ë¦¬ëŠ” ì‚¶ì„ ë°”ê¾¸ëŠ”ê°€, ì•„ë‹ˆë©´ ë‚¨ì„ ì‹¬íŒí•˜ëŠ” ë„êµ¬ì¸ê°€?"

def op_being_unconceal(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¥¼ â€˜ì •í™•í•œ ëª…ì œâ€™ë¡œë§Œ ë³´ì§€ ë§ˆë¼. ì§„ë¦¬ëŠ” ë“œëŸ¬ë‚¨(ì•Œë ˆí…Œì´ì•„)ì´ë‹¤."
    g.warrant = "ë¬´ì—‡ì´ ìˆ¨ê²¨ì§€ê³  ë¬´ì—‡ì´ ë“œëŸ¬ë‚˜ëŠ”ì§€, ê·¸ êµ¬ì¡°ë¥¼ ë³´ë¼."
    g.constraint = "ë¨¼ì € â€˜ì¡´ì¬â€™ê°€ ì–´ë–»ê²Œ ì—´ë¦¬ëŠ”ì§€ ë¬¼ì–´ì•¼ í•œë‹¤."

def op_existential_choice(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¥¼ ì°¾ê² ë‹¤ëŠ” ë§ì€ ê²°êµ­ ì„ íƒì˜ ë¬¸ì œë‹¤."
    g.warrant = "ë„ˆëŠ” ì„ íƒí•˜ì§€ ì•Šì„ ììœ ë„ ì—†ë‹¤. ì¹¨ë¬µë„ í•˜ë‚˜ì˜ ì„ íƒì´ë‹¤."
    g.attack = "ë„ˆì˜ ì§„ë¦¬ëŠ” ì±…ì„ì„ ì§€ê²Œ ë§Œë“œëŠ”ê°€, ì±…ì„ì„ íšŒí”¼í•˜ê²Œ ë§Œë“œëŠ”ê°€?"

def op_marx_ideology(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ëŠ” ë¨¸ë¦¬ì—ì„œ ë–¨ì–´ì§„ ë³„ì´ ì•„ë‹ˆë‹¤. ìƒì‚°ê³¼ ì œë„ì˜ ë°”ë‹¥ì—ì„œ ë§Œë“¤ì–´ì§„ë‹¤."
    g.warrant = "ì§€ë°°ì  ì§„ë¦¬ëŠ” ì§€ë°°ì  ê´€ê³„ë¥¼ ì •ë‹¹í™”í•˜ëŠ” ê²½í–¥ì´ ìˆë‹¤."
    g.attack = "ëˆ„ê°€ ê·¸ ì§„ë¦¬ë¡œ ì´ë“ì„ ë³´ëŠ”ì§€ë¶€í„° ë³´ë¼."

def op_utilitarian(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¥¼ ë…¼í•  ë•Œ, ê²°ê³¼ì˜ íŒŒê¸‰ì„ ê³„ì‚°ì—ì„œ ì œì™¸í•  ìˆ˜ ì—†ë‹¤."
    g.warrant = "ê·œì¹™ì€ í–‰ë³µ/ê³ í†µì˜ ì´ëŸ‰ê³¼ ì—°ê²°ë  ë•Œ ì„¤ë“ë ¥ì„ ì–»ëŠ”ë‹¤."
    g.constraint = "ë”°ë¼ì„œ ì–´ë–¤ ë§ì´ ì‹¤ì œë¡œ ì–´ë–¤ í”¼í•´/ì´ë“ì„ ë§Œë“œëŠ”ì§€ ë³´ë¼."

def op_falsification(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¼ê³  ì£¼ì¥í•œë‹¤ë©´, ì–´ë–¤ ì¡°ê±´ì—ì„œ ê·¸ ì£¼ì¥ì´ ë°˜ë°•ë˜ëŠ”ì§€ ë¨¼ì € ë§í•´ì•¼ í•œë‹¤."
    g.warrant = "ë°˜ë°• ê°€ëŠ¥ì„±ì´ ì—†ëŠ” í™•ì‹ ì€ ì§€ì‹ì´ ì•„ë‹ˆë¼ ì‹ ë…ì´ë‹¤."
    g.attack = "ë„ˆì˜ ì§„ë¦¬ëŠ” ìœ„í—˜ì„ ê°ìˆ˜í•˜ëŠ”ê°€, ì•„ë‹ˆë©´ ë„ë§ì¹˜ê¸° ì‰¬ìš´ê°€?"

def op_original_position(p, topic, other, g, t, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ì˜ ê·œì¹™ì„ ì„¸ìš´ë‹¤ë©´, ë‚´ê°€ ëˆ„êµ¬ì¸ì§€ ëª¨ë¥´ëŠ” ìƒíƒœì—ì„œ ê·¸ ê·œì¹™ì„ ì„ íƒí•˜ê² ëŠ”ê°€?"
    g.warrant = "ê³µì •ì€ ìê¸° ì´ìµì„ ê°€ë¦¬ëŠ” ì¥ì¹˜ì—ì„œ ì‹œí—˜ëœë‹¤."
    g.constraint = "ê·¸ëŸ¬ë‹ˆ ëª¨ë‘ê°€ ë°›ì•„ë“¤ì¼ ìˆ˜ ìˆëŠ” ì¡°ê±´ì„ ë¨¼ì € ì„¸ì›Œë¼."

OPS = {
    "define_split": op_define_split,
    "condition_censor": op_condition_censor,
    "empirical_classify": op_empirical_classify,
    "reductio": op_reductio,
    "genealogy_expose": op_genealogy_expose,
    "value_invert": op_value_invert,
    "language_therapy": op_language_therapy,
    "power_knowledge": op_power_knowledge,
    "public_world": op_public_world,
    "elenchus": op_elenchus,
    "methodic_doubt": op_methodic_doubt,
    "hume_skeptic": op_hume_skeptic,
    "dialectic": op_dialectic,
    "pessimism_will": op_pessimism_will,
    "subjective_truth": op_subjective_truth,
    "being_unconceal": op_being_unconceal,
    "existential_choice": op_existential_choice,
    "marx_ideology": op_marx_ideology,
    "utilitarian": op_utilitarian,
    "falsification": op_falsification,
    "original_position": op_original_position,
}

# --- Helpers ---
def apply_taboo_repairs(p: Philosopher, text: str, hits: List[InferenceTaboo], topic: str) -> str:
    if not hits: return text
    repairs = []
    for h in hits[:2]:
        if "ê°€ëŠ¥ì¡°ê±´" in h.repair_hint: repairs.append("ì¤‘ìš”í•œ ê±´ 'ê°€ëŠ¥ ì¡°ê±´'ì…ë‹ˆë‹¤.")
        elif "ì¡´ì—„" in h.repair_hint: repairs.append("ì–´ë–¤ ëª©ì ë„ ì¡´ì—„ì„ í•´ì¹  ìˆœ ì—†ìŠµë‹ˆë‹¤.")
        elif "ê³„ë³´í•™" in h.repair_hint: repairs.append("ëˆ„ê°€ ì„ ì´ë¼ ë¶€ë¥´ë©° í˜ì„ ì–»ëŠ”ê°€?")
        elif "ê°€ì¹˜ì „ë„" in h.repair_hint: repairs.append("â€˜ì§„ë¦¬ê°€ ì™œ ì„ ì¸ê°€â€™ë¶€í„° ë‹¤ì‹œ ë¬»ì.")
        elif "ìŠµê´€" in h.repair_hint: repairs.append("'í•„ì—°'ì€ ë‹¨ì§€ ìŠµê´€ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif "ì–¸ì–´ ì‚¬ìš©" in h.repair_hint: repairs.append("ê·¸ ë‹¨ì–¸ì€ ì–¸ì–´ì˜ ì˜¤ìš©ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif "ê¶Œë ¥-ì§€ì‹" in h.repair_hint: repairs.append("ì§„ë¦¬ëŠ” ê¶Œë ¥ ì¥ì¹˜ì™€ ì–½í˜€ ìˆìŠµë‹ˆë‹¤.")
    soft = pick(p.lexicon.taboo_softeners)
    add = (" " + soft + " " if soft else " ") + " ".join(repairs)
    return (text + add).strip()

def ensure_concept_anchor(p: Philosopher, text: str) -> str:
    cg = concept_graph_score(p.name, text)
    if cg >= 0.24: return text
    anchors = {
        "ì¹¸íŠ¸": " ë³´í¸ íƒ€ë‹¹ì„±ì„ ìœ„í•´ì„  ê°€ëŠ¥ ì¡°ê±´ì„ ìš”êµ¬í•´ì•¼ í•©ë‹ˆë‹¤.",
        "ë‹ˆì²´": " ê²°êµ­ ê·¸ 'ì§„ë¦¬'ëŠ” ê°€ì¹˜ì˜ ê°€ë©´ì´ë‹¤!",
        "í”Œë¼í†¤": " ë³€í•˜ì§€ ì•ŠëŠ” ê¸°ì¤€ì´ ì—†ìœ¼ë©´ ì§„ë¦¬ëŠ” í©ì–´ì§‘ë‹ˆë‹¤.",
        "ì•„ë¦¬ìŠ¤í† í…”ë ˆìŠ¤": " ì‚¬ë¡€ì™€ ì›ì¸ ë¶„ì„ìœ¼ë¡œ ë§ì„ ì„¸ì›Œì•¼ í•©ë‹ˆë‹¤.",
        "ì†Œí¬ë¼í…ŒìŠ¤": " ë„ˆëŠ” ê·¸ê²ƒì„ ì§„ì •ìœ¼ë¡œ ì•„ëŠ”ê°€?",
        "ë°ì¹´ë¥´íŠ¸": " ë‚˜ëŠ” ìƒê°í•œë‹¤, ê³ ë¡œ ì¡´ì¬í•œë‹¤.",
        "ë§ˆë¥´í¬ìŠ¤": " ë¬¸ì œëŠ” í•´ì„ì´ ì•„ë‹ˆë¼ ë³€í˜ì´ë‹¤.",
        "ë¹„íŠ¸ê²ìŠˆíƒ€ì¸": " ë§í•  ìˆ˜ ì—†ëŠ” ê²ƒì—” ì¹¨ë¬µí•´ì•¼ í•©ë‹ˆë‹¤.",
    }
    return (text + anchors.get(p.name, "")).strip()

def build_arggraph(p: Philosopher, topic: str, other_claim: str, tension: float, mode: str, entropy_boost: float = 0.0) -> ArgGraph:
    g = ArgGraph()
    raw_ops = p.reasoning.ops
    unique_ops = list(dict.fromkeys(raw_ops))

    atk_bias = 0.9 + 0.8 * p.phase.get("attack", 0.5)
    syn_bias = 0.9 + 0.8 * p.phase.get("synthesize", 0.5)
    open_bias = 0.9 + 0.6 * p.phase.get("open", 0.5)
    reg = tension_to_register(tension)
    weights = []

    attack_ops = {"reductio", "genealogy_expose", "power_knowledge", "value_invert", "hume_skeptic", "pessimism_will", "marx_ideology", "elenchus"}
    syn_ops = {"public_world", "define_split", "dialectic", "utilitarian"}
    open_ops = {"define_split", "empirical_classify", "condition_censor", "language_therapy", "methodic_doubt", "being_unconceal", "original_position", "falsification"}

    for opn in unique_ops:
        w = 1.0
        if mode == "attack" and opn in attack_ops: w *= atk_bias
        if mode == "synthesize" and opn in syn_ops: w *= syn_bias
        if mode == "open" and opn in open_ops: w *= open_bias
        if reg == "high": w *= (1.0 + 0.6 * p.style.rhetoric_bias)
        elif reg == "low": w *= (1.0 + 0.6 * p.style.justification_bias)
        weights.append(w)

    probs = softmax(weights, temp=0.9 + entropy_boost)
    k = 3 if reg != "low" else 2
    if entropy_boost > 0.0 and len(unique_ops) >= 4:
        k += 1

    chosen: Set[str] = set()
    attempts = 0
    target_k = min(k, len(unique_ops))
    while len(chosen) < target_k and attempts < 20:
        attempts += 1
        r = random.random()
        cum = 0.0
        for opn, pr in zip(unique_ops, probs):
            cum += pr
            if r <= cum:
                chosen.add(opn)
                break

    if len(chosen) < target_k:
        remaining = [op for op in unique_ops if op not in chosen]
        if remaining:
            chosen.update(random.sample(remaining, min(len(remaining), target_k - len(chosen))))

    ordered_chosen = [op for op in unique_ops if op in chosen]
    target = pick_target_concept_from_other(other_claim, fallback=topic)
    for opn in ordered_chosen:
        OPS[opn](p, topic, other_claim, g, tension, target=target)
    return g

def linearize(p: Philosopher, g: ArgGraph, tension: float) -> str:
    reg = tension_to_register(tension)
    if reg == "low":
        lead = pick(p.lexicon.hedges) or "ì•„ë§ˆë„"
    elif reg == "mid":
        lead = "ê·¸ëŸ¬ë‚˜"
    else:
        lead = pick(p.lexicon.intensifiers) or "ë‹¨í˜¸íˆ"

    parts: List[str] = []
    if p.style.interrogation_bias > 0.65:
        parts.append(f"{lead}, ë¨¼ì € ë¬»ê² ìŠµë‹ˆë‹¤.")

    if reg == "high" and p.style.rhetoric_bias >= p.style.justification_bias:
        if g.attack: parts.append(g.attack)
        if g.claim: parts.append(g.claim)
        if g.warrant: parts.append(g.warrant)
        if g.constraint: parts.append(g.constraint)
        if g.synthesis: parts.append(g.synthesis)
    else:
        if g.claim: parts.append(f"{lead}, {g.claim}")
        if g.warrant: parts.append(g.warrant)
        if g.constraint: parts.append(g.constraint)
        if g.attack: parts.append(g.attack)
        if g.synthesis: parts.append(g.synthesis)

    if p.style.poetic_bias > 0.6 and p.lexicon.metaphors:
        parts.insert(0, pick(p.lexicon.metaphors))

    text = " ".join([s.strip() for s in parts if s and s.strip()])
    if random.random() < 0.25:
        core_word = pick(p.lexicon.core)
        if core_word:
            text = f"({core_word}) {text}"

    if p.name == "ë‹ˆì²´":
        text = text.replace("í•©ë‹ˆë‹¤", "í•œë‹¤").replace("ì…ë‹ˆë‹¤", "ì´ë‹¤")
        if reg == "high":
            text = text.replace(".", "!")
    return text.strip()

@dataclass
class Verdict:
    status: str
    note: str
    tension: float
    coherence: float
    novelty: float
    is_warmup: bool = False

class Arbiter:
    def __init__(self, cast_size: int):
        self.t_hist: List[float] = []
        self.c_hist: List[float] = []
        self.n_hist: List[float] = []
        self.last: List[str] = []
        self.p_last: Dict[str, str] = {}
        self.warmup_turns = cast_size * WARMUP_CAST_PASSES
        self.window_size = WINDOW_SIZE
        self.turn_count = 0
        self.warmup_done = False
        self.calibration_snapshot = (0.0, 0.0, 0.0)

    def novelty_check(self, text: str, speaker: str) -> float:
        toks = tokenize(text)
        glob_n = 1.0
        if self.last:
            window = self.last[-self.window_size:]
            max_sim = max([jaccard(toks, tokenize(prev)) for prev in window], default=0.0)
            glob_n = clamp(1.0 - max_sim, 0.0, 1.0)

        pers_n = 1.0
        if speaker in self.p_last:
            prev_p = tokenize(self.p_last[speaker])
            pers_n = clamp(1.0 - jaccard(toks, prev_p), 0.0, 1.0)

        return (glob_n * 0.4) + (pers_n * 0.6)

    def judge(self, text: str, speaker: str) -> Verdict:
        t_raw = sum(1 for m in ["ë¶•ê´´", "í­ë¡œ", "ê²€ì—´", "ë°°ì œ", "ë„ì•½", "ìœ„ì„ ", "ì§€ë°°", "ê°€ë©´", "ìš°ìƒ", "ë…ì ", "íˆ¬ìŸ"] if m in text) + min(2, text.count("!") // 2)
        t = clamp(t_raw / 6.0, 0.0, 1.0)
        c_density = clamp(len(extract_concepts(text)) / 6.0, 0.0, 1.0)
        c = clamp(c_density, 0.0, 1.0)
        n = self.novelty_check(text, speaker)

        self.turn_count += 1
        self.t_hist.append(t)
        self.c_hist.append(c)
        self.n_hist.append(n)
        self.last.append(text)
        self.p_last[speaker] = text

        if not self.warmup_done:
            if self.turn_count < self.warmup_turns:
                return Verdict("CONTINUE", "(Warm-up)", t, c, n, is_warmup=True)
            elif self.turn_count == self.warmup_turns:
                self.calibration_snapshot = (t, c, n)
                self.warmup_done = True
                self.t_hist.clear()
                self.c_hist.clear()
                self.n_hist.clear()
                self.last.clear()
                self.p_last.clear()  # [Method] Total Amnesia for fresh start
                return Verdict("RESET", f"(Calibration Complete) [Snap: T{t:.2f}/C{c:.2f}/N{n:.2f}]", t, c, n, is_warmup=True)

        if len(self.t_hist) >= 5:
            if (sum(1 for x in self.t_hist[-5:] if x > 0.80) >= 4) and (sum(1 for y in self.c_hist[-5:] if y < 0.28) >= 3):
                return Verdict("MELTDOWN", "íŒŒêµ­ ì„ë°•.", t, c, n)

        if len(self.n_hist) >= 6:
            if sum(1 for x in self.n_hist[-6:] if x < 0.25) >= 5:
                return Verdict("DEADLOCK", "êµì°© ìƒíƒœ.", t, c, n)

        if len(self.t_hist) >= 6:
            th = self.t_hist
            ch = self.c_hist
            if th[-6] > 0.70 and th[-1] < 0.35 and ch[-1] > 0.45:
                return Verdict("CONSENSUS", "ê³µëª… ë°œìƒ.", t, c, n)

        return Verdict("CONTINUE", "", t, c, n)

    def adapt(self, philos: List[Philosopher], verdict: Verdict):
        if verdict.status == "RESET":
            (t, c, n) = self.calibration_snapshot
            for p in philos:
                p.phase["open"] = clamp(p.phase["open"] + 0.1 * n, 0.0, 1.0)
            return

        if verdict.is_warmup:
            return

        for p in philos:
            if verdict.status == "MELTDOWN":
                p.phase["attack"] = clamp(p.phase["attack"] - 0.15, 0.0, 1.0)
                p.phase["open"] = clamp(p.phase["open"] + 0.10, 0.0, 1.0)
                p.phase["synthesize"] = clamp(p.phase["synthesize"] + 0.10, 0.0, 1.0)
            elif verdict.status == "DEADLOCK":
                p.phase["open"] = clamp(p.phase["open"] + 0.15, 0.0, 1.0)
                p.phase["attack"] = clamp(p.phase["attack"] + 0.05, 0.0, 1.0)
            elif verdict.status == "CONSENSUS":
                p.phase["synthesize"] = clamp(p.phase["synthesize"] + 0.15, 0.0, 1.0)
                p.phase["attack"] = clamp(p.phase["attack"] - 0.10, 0.0, 1.0)
            else:
                for k in p.phase:
                    p.phase[k] = clamp(p.phase[k] * 0.98 + 0.01, 0.0, 1.0)

def build_user_philosopher(user_claim: str) -> Philosopher:
    cs = extract_concepts(user_claim or "")
    if not cs:
        cs = {"ì§„ë¦¬"}
    vec = {c: 1.0 for c in cs}
    soft_mix = ["ê·¸ëŸ°ë°", "í•˜ì§€ë§Œ", "ì œ ìƒê°ì—”", "ìš”ì§€ëŠ”", "ì •ë¦¬í•˜ë©´,"]
    lex = Lexicon(
        core=["ë‚˜ì˜ ì£¼ì¥", "ì§ê´€", "ì‚¬ë¡€"],
        evidentials=["ì œê°€ ë³´ê¸°ì—”", "ê²½í—˜ìƒ", "ìƒê°í•´ë³´ë©´"],
        hedges=["ì•„ë§ˆ", "ê°€ëŠ¥ì„±ì€", "ì¼ë‹¨"],
        intensifiers=["í™•ì‹¤íˆ", "ë¶„ëª…íˆ", "ê°•í•˜ê²Œ"],
        metaphors=["ë§ì€ ì§€ë„ì´ê³ , ì„¸ê³„ëŠ” ì§€í˜•ì…ë‹ˆë‹¤."],
        taboo_softeners=soft_mix,
    )
    style = StyleProfile(rhetoric_bias=0.55, justification_bias=0.65, interrogation_bias=0.60, poetic_bias=0.20)
    ops = ["define_split", "empirical_classify", "falsification", "elenchus"]
    return Philosopher(name="ì‚¬ìš©ì", era="í˜„ëŒ€", truth_vector=vec, lexicon=lex, reasoning=ReasoningOps(ops), taboo=[], style=style)

def build_grand_cast() -> List[Philosopher]:
    def L(core, evid, hed, inten, meta, soft): return Lexicon(core, evid, hed, inten, meta, soft)
    def S(rhet, just, inter, poet): return StyleProfile(rhet, just, inter, poet)
    def P(name, era, vec, lex, ops, taboo, style): return Philosopher(name, era, vec, lex, ReasoningOps(ops), taboo, style)

    soft_mix = ["ê·¸ëŸ¬ë‚˜", "í•˜ì§€ë§Œ", "ë‹¤ë§Œ", "ê·¸ëŸ¼ì—ë„", "ë¬¼ë¡ ,", "ì¸ì •í•©ë‹ˆë‹¤ë§Œ,"]
    return [
        P("í”Œë¼í†¤","ê³ ëŒ€",{"í˜•ì´ìƒ":0.90,"ë³´í¸":0.92,"ì´ì„±":0.80}, L(["ì´ë°ì•„","ë³¸ì§ˆ"],["ìš°ì„ "],["ì•„ë§ˆë„"],["ë‹¨í˜¸íˆ"],["ê·¸ë¦¼ìë¥¼ ë³´ë©° ì§„ë¦¬ë¥¼ ë§í•  ìˆœ ì—†ìŠµë‹ˆë‹¤."],soft_mix), ["define_split","reductio","condition_censor"],[],S(0.55,0.65,0.55,0.35)),
        P("ì•„ë¦¬ìŠ¤í† í…”ë ˆìŠ¤","ê³ ëŒ€",{"ê²½í—˜":0.88,"ì´ì„±":0.75,"ë°©ë²•":0.80}, L(["ì›ì¸","ë¶„ë¥˜"],["ê´€ì°°í•˜ìë©´"],["ëŒ€ì²´ë¡œ"],["ì •í™•íˆ"],["ëŒ€ìƒì„ í•´ë¶€ëŒ€ ìœ„ì— ì˜¬ë ¤ì•¼ í•©ë‹ˆë‹¤."],soft_mix), ["empirical_classify","define_split"],[],S(0.35,0.85,0.35,0.10)),
        P("ì¹¸íŠ¸","ê·¼ëŒ€",{"ì´ì„±":0.90,"ë³´í¸":0.88,"ë„ë•":0.82}, L(["ê°€ëŠ¥ ì¡°ê±´","ë³´í¸ íƒ€ë‹¹ì„±"],["ë”°ì ¸ë³´ë©´"],["ìš°ì„ "],["ê²°ì½”"],["ê·œì¹™ ì—†ëŠ” íŒë‹¨ì€ ë‚˜ì¹¨ë°˜ ì—†ëŠ” í•­í•´ì…ë‹ˆë‹¤."],soft_mix), ["condition_censor","reductio"], [TABOOS["kant_empirical_jump"]], S(0.30,0.95,0.75,0.05)),
        P("ë‹ˆì²´","í˜„ëŒ€",{"ê¶Œë ¥":0.90,"ê°€ì¹˜":0.85,"ì§„ë¦¬":0.55}, L(["ë§ì¹˜","ìš°ìƒ","í˜"],["ë³´ë¼"],["ë•Œë•Œë¡œ"],["ê°€ì°¨ì—†ì´"],["ì§„ë¦¬ëŠ” ì•½ìì˜ ìœ„ì•ˆì´ì ê°•ìì˜ ë„êµ¬ë‹¤."],soft_mix), ["genealogy_expose","value_invert","reductio"], [TABOOS["nietzsche_universal_morals"]], S(0.90,0.45,0.55,0.75)),
        P("ì†Œí¬ë¼í…ŒìŠ¤","ê³ ëŒ€",{"ë°©ë²•":0.95,"ì£¼ì²´":0.75}, L(["ë°˜ë¬¸","ë¬´ì§€"],["ê·¸ë ‡ë‹¤ë©´"],["ì•„ë§ˆ"],["ë¶„ëª…íˆ"],["ë‚˜ëŠ” ë‚´ê°€ ëª¨ë¥¸ë‹¤ëŠ” ê²ƒì„ ì•ˆë‹¤."],soft_mix), ["elenchus","define_split"],[],S(0.45,0.60,0.95,0.05)),
        P("ë°ì¹´ë¥´íŠ¸","ê·¼ëŒ€",{"ì£¼ì²´":0.92,"ì´ì„±":0.85}, L(["ëª…ì„íŒëª…","ì˜ì‹¬"],["ë‹¨í˜¸íˆ"],["ì¼ë‹¨"],["í™•ì‹¤íˆ"],["í”ë“¤ë¦¬ëŠ” ê²ƒì€ ëª¨ë‘ ê±·ì–´ë‚´ë¼."],soft_mix), ["methodic_doubt","define_split"],[],S(0.40,0.85,0.55,0.10)),
        P("í„","ê·¼ëŒ€",{"ê²½í—˜":0.92,"ë°©ë²•":0.80}, L(["ìŠµê´€","ì¸ìƒ"],["ê²½í—˜ìƒ"],["ëŒ€ê°œ"],["ê²°êµ­"],["ìš°ë¦¬ëŠ” ë…¼ë¦¬ë³´ë‹¤ ë¯¿ìŒì„ ë¨¼ì € ë°°ìš´ë‹¤."],soft_mix), ["hume_skeptic","empirical_classify"], [TABOOS["hume_necessary_causation"]], S(0.25,0.80,0.55,0.10)),
        P("ìŠ¤í”¼ë…¸ì","ê·¼ëŒ€",{"ì¡´ì¬":0.90,"ì´ì„±":0.85}, L(["í•„ì—°","ìì—°"],["í•„ì—°ì ìœ¼ë¡œ"],["ì •í™•íˆ"],["ë°˜ë“œì‹œ"],["ìì—°ì€ ë³€ë•ì´ ì•„ë‹ˆë¼ ì§ˆì„œë‹¤."],soft_mix), ["define_split","reductio"],[],S(0.35,0.90,0.45,0.10)),
        P("ë§ˆë¥´í¬ìŠ¤","ê·¼ëŒ€",{"ì‚¬íšŒ":0.92,"ì—­ì‚¬":0.85,"ê¶Œë ¥":0.85}, L(["ê³„ê¸‰","ìƒì‚°"],["í˜„ì‹¤ì ìœ¼ë¡œ"],["ëŒ€ê°œ"],["ë‹¨í˜¸íˆ"],["ì¤‘ìš”í•œ ê²ƒì€ í•´ì„ì´ ì•„ë‹ˆë¼ ë³€í˜ì´ë‹¤."],soft_mix), ["marx_ideology","power_knowledge"],[],S(0.70,0.55,0.55,0.20)),
        P("ë¹„íŠ¸ê²ìŠˆíƒ€ì¸","í˜„ëŒ€",{"ì–¸ì–´":0.95,"ë°©ë²•":0.85}, L(["ì–¸ì–´ê²Œì„","ê·œì¹™"],["ë³´ìë©´"],["ì•„ë§ˆë„"],["ì •í™•íˆ"],["ë§í•  ìˆ˜ ì—†ëŠ” ê²ƒì—” ì¹¨ë¬µí•˜ë¼."],soft_mix), ["language_therapy","define_split"], [TABOOS["witt_metaphysics_assert"]], S(0.25,0.85,0.55,0.10)),
        P("í—¤ê²”","ê·¼ëŒ€",{"ì—­ì‚¬":0.92,"ë°©ë²•":0.85,"ì§„ë¦¬":0.75}, L(["ë³€ì¦","ì „ê°œ"],["ë”°ë¼ê°€ë©´"],["ì¼ë‹¨"],["ê²°êµ­"],["ì§„ë¦¬ëŠ” ê³¼ì •ì´ë‹¤."],soft_mix), ["dialectic","define_split"],[],S(0.55,0.65,0.45,0.15)),
        P("ì‡¼íœí•˜ìš°ì–´","ê·¼ëŒ€",{"ì£¼ì²´":0.75,"ì¡´ì¬":0.70,"ê°€ì¹˜":0.65}, L(["ê³ í†µ","ì˜ì§€"],["ì†”ì§íˆ"],["ëŒ€ê°œ"],["ë‹¨í˜¸íˆ"],["ì‚¶ì€ ê³ í†µì˜ ì§„ìë‹¤."],soft_mix), ["pessimism_will","define_split"],[],S(0.55,0.55,0.55,0.25)),
        P("í‚¤ë¥´ì¼€ê³ ë¥´","ê·¼ëŒ€",{"ì£¼ì²´":0.90,"ê°€ì¹˜":0.80}, L(["ì‹¤ì¡´","ê²°ë‹¨"],["ë¨¼ì €"],["ì–´ì©Œë©´"],["ê²°êµ­"],["ì§„ë¦¬ëŠ” ì‚´ì•„ë‚´ëŠ” ê²ƒì´ë‹¤."],soft_mix), ["subjective_truth","existential_choice"],[],S(0.60,0.55,0.70,0.35)),
        P("í•˜ì´ë°ê±°","í˜„ëŒ€",{"ì¡´ì¬":0.92,"ì£¼ì²´":0.75}, L(["ì¡´ì¬","ë“œëŸ¬ë‚¨"],["ë¨¼ì €"],["ì–´ì©Œë©´"],["ê²°êµ­"],["ì§„ë¦¬ëŠ” ìˆ¨ê¹€ê³¼ ë“œëŸ¬ë‚¨ì˜ ì‹¸ì›€ì´ë‹¤."],soft_mix), ["being_unconceal","define_split"],[],S(0.55,0.60,0.55,0.25)),
        P("ì‚¬ë¥´íŠ¸ë¥´","í˜„ëŒ€",{"ììœ ":0.92,"ì£¼ì²´":0.88}, L(["ììœ ","ì±…ì„"],["ë‹¨í˜¸íˆ"],["ë•Œë•Œë¡œ"],["ê²°êµ­"],["ì¸ê°„ì€ ììœ ë¼ëŠ” í˜•ë²Œì„ ë°›ì•˜ë‹¤."],soft_mix), ["existential_choice","define_split"],[],S(0.70,0.55,0.55,0.30)),
        P("í‘¸ì½”","í˜„ëŒ€",{"ì‚¬íšŒ":0.90,"ê¶Œë ¥":0.90}, L(["ê·œìœ¨","ì¥ì¹˜"],["ì¶”ì í•˜ë©´"],["ëŒ€ê°œ"],["ë¶„ëª…íˆ"],["ì§„ë¦¬ëŠ” ì¥ì¹˜ ì†ì—ì„œ ìƒì‚°ëœë‹¤."],soft_mix), ["power_knowledge","genealogy_expose"], [TABOOS["foucault_truth_neutral"]], S(0.70,0.55,0.55,0.20)),
        P("ì•„ë ŒíŠ¸","í˜„ëŒ€",{"ì‚¬íšŒ":0.90,"ê°€ì¹˜":0.78}, L(["ê³µì ì„¸ê³„","í–‰ìœ„"],["ë³´ìë©´"],["ì–´ì©Œë©´"],["ë¶„ëª…íˆ"],["ì§„ë¦¬ëŠ” ì„¸ê³„ë¥¼ í•¨ê»˜ ë“œëŠ” ê²ƒì´ë‹¤."],soft_mix), ["public_world","define_split"],[],S(0.45,0.70,0.55,0.15)),
        P("í¬í¼","í˜„ëŒ€",{"ë°©ë²•":0.92,"ê²½í—˜":0.80}, L(["ë°˜ì¦","ê°€ì„¤"],["ë¨¼ì €"],["ì¼ë‹¨"],["ë¶„ëª…íˆ"],["ì§€ì‹ì€ ë°˜ë°•ì„ í†µí•´ ìë€ë‹¤."],soft_mix), ["falsification","empirical_classify"],[],S(0.35,0.80,0.55,0.05)),
        P("ë¡¤ìŠ¤","í˜„ëŒ€",{"ë„ë•":0.90,"ì‚¬íšŒ":0.85}, L(["ê³µì •","ì›ì´ˆìƒíƒœ"],["ê°€ì •í•´ë³´ë©´"],["ì¼ë‹¨"],["ë¶„ëª…íˆ"],["ê·œì¹™ì€ ì•½ìì˜ ìë¦¬ì—ì„œ ê²¬ëŒì•¼ í•œë‹¤."],soft_mix), ["original_position","condition_censor"],[],S(0.35,0.85,0.55,0.05)),
        P("ë¼ì´í”„ë‹ˆì¸ ","ê·¼ëŒ€",{"ì´ì„±":0.88,"ë³´í¸":0.85}, L(["ì¶©ë¶„ì´ìœ ","ì¡°í™”"],["ë”°ì ¸ë³´ë©´"],["ì•„ë§ˆë„"],["í•„ì—°ì ìœ¼ë¡œ"],["ì™œ ë¬´ê°€ ì•„ë‹ˆë¼ ìœ ì¸ê°€?"],soft_mix), ["condition_censor","define_split"],[],S(0.35,0.85,0.55,0.20)),
    ]

class Agora:
    def __init__(self, cast, seed=None):
        self.philos = cast
        self.seed = seed
        self.arb = Arbiter(len(cast))
        self.positions: Dict[str, str] = {}

    def _pick_other(self, i, r):
        n = len(self.philos)
        if n <= 1:
            return self.philos[i]
        j = (i + r) % n
        if j == i:
            j = (i + r + 1) % n
        return self.philos[j]

    async def run_async_generator(self, topic: str, rounds: int = 5, state_lock: asyncio.Lock = None, stop_event: asyncio.Event = None):
        yield f"ğŸ›ï¸ Grand Agora v27.1 (Production Ready) | ì£¼ì œ: {topic}"
        yield f"ì°¸ì—¬ ({len(self.philos)}ëª…): {', '.join(p.name for p in self.philos[:5])}..."
        yield "-" * 50
        yield "\n[ğŸ¤ ê°œíšŒì‚¬ ë° ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì§„í–‰ ì¤‘...]"

        base_tension = 0.28

        if state_lock:
            async with state_lock:
                if "ì‚¬ìš©ì" not in self.positions:
                    self.positions["ì‚¬ìš©ì"] = f"ì €ëŠ” '{topic}'ì— ëŒ€í•´, ìµœì†Œí•œ ë°˜ë°• ê°€ëŠ¥ì„±(ê²€ì¦/ë°˜ì¦)ì´ ìˆì–´ì•¼ ì§„ë¦¬ì— ê°€ê¹ë‹¤ê³  ë´…ë‹ˆë‹¤."
        else:
            if "ì‚¬ìš©ì" not in self.positions:
                self.positions["ì‚¬ìš©ì"] = f"ì €ëŠ” '{topic}'ì— ëŒ€í•´, ìµœì†Œí•œ ë°˜ë°• ê°€ëŠ¥ì„±(ê²€ì¦/ë°˜ì¦)ì´ ìˆì–´ì•¼ ì§„ë¦¬ì— ê°€ê¹ë‹¤ê³  ë´…ë‹ˆë‹¤."

        opening_buffer: Dict[str, str] = {}
        for p in self.philos:
            if stop_event and stop_event.is_set():
                return

            if p.name == "ì‚¬ìš©ì":
                if state_lock:
                    async with state_lock:
                        s = self.positions["ì‚¬ìš©ì"]
                else:
                    s = self.positions["ì‚¬ìš©ì"]
                opening_buffer[p.name] = s
                self.arb.p_last[p.name] = s
                yield f"[ê°œíšŒì‚¬] ì‚¬ìš©ì: {s[:60]}..."
            else:
                g = build_arggraph(p, topic, "", base_tension, "open")
                s = linearize(p, g, base_tension)
                s = ensure_concept_anchor(p, s)
                opening_buffer[p.name] = s
                self.arb.p_last[p.name] = s
                if random.random() < 0.25:
                    yield f"[ê°œíšŒì‚¬] {p.name}: {s[:60]}..."
            await asyncio.sleep(0.01)

        if state_lock:
            async with state_lock:
                self.positions.update(opening_buffer)
        else:
            self.positions.update(opening_buffer)

        for r in range(1, rounds + 1):
            if stop_event and stop_event.is_set():
                return
            yield f"\nğŸŒ€ Round {r}"
            yield "-" * 50

            for i, me in enumerate(self.philos):
                if stop_event and stop_event.is_set():
                    return

                if me.name == "ì‚¬ìš©ì":
                    if state_lock:
                        async with state_lock:
                            s = self.positions.get("ì‚¬ìš©ì", "").strip()
                    else:
                        s = self.positions.get("ì‚¬ìš©ì", "").strip()

                    if not s:
                        yield "\nğŸ—£ï¸ ì‚¬ìš©ì: (ì´ë²ˆ í„´ì€ ë°œì–¸ ì—†ìŒ)"
                        continue

                    verdict = self.arb.judge(s, me.name)
                    hud = f"   ğŸ“Š [Mode:USER->USER   | Fric:0.00] (T:{verdict.tension:.2f} C:{verdict.coherence:.2f} N:{verdict.novelty:.2f})"
                    yield f"\nğŸ—£ï¸ ì‚¬ìš©ì:\n\"{s}\""
                    yield hud
                    self.arb.adapt(self.philos, verdict)
                    await asyncio.sleep(0.1)
                    continue

                other = self._pick_other(i, r)

                if state_lock:
                    async with state_lock:
                        other_claim = self.positions.get(other.name, "")
                else:
                    other_claim = self.positions.get(other.name, "")

                dist = 1.0 - cosine_sim(me.truth_vector, other.truth_vector)

                if not other_claim.strip():
                    friction = clamp(0.55 * dist + 0.05, 0.0, 1.0)
                else:
                    other_cg = concept_graph_score(me.name, other_claim)
                    taboo_s, _ = taboo_score(me.taboo, other_claim)
                    friction = clamp(0.55 * dist + 0.25 * taboo_s + 0.20 * (1.0 - other_cg), 0.0, 1.0)

                if friction > 0.60:
                    mode = "attack"
                elif friction > 0.35:
                    mode = "open"
                else:
                    mode = "synthesize"

                tension = clamp(0.30 + 0.70 * friction, 0.0, 1.0)
                g = build_arggraph(me, topic, other_claim, tension, mode)
                s = linearize(me, g, tension)

                ts, hits = taboo_score(me.taboo, s)
                if ts > 0.55:
                    s = apply_taboo_repairs(me, s, hits, topic)

                s = ensure_concept_anchor(me, s)

                n0 = self.arb.novelty_check(s, me.name)
                re_roll_msg = ""
                if n0 < RE_ROLL_THRESHOLD and me.style.rhetoric_bias > RHETORIC_THRESHOLD:
                    cands = {"attack", "open", "synthesize"} - {mode}
                    new_mode = random.choice(list(cands))
                    mode_display = f"{mode.upper()}->{new_mode.upper()}"
                    mode = new_mode
                    tension_boost = clamp(tension + 0.25, 0.0, 1.0)
                    g2 = build_arggraph(me, topic, other_claim, tension_boost, mode, entropy_boost=0.3)
                    s2 = linearize(me, g2, tension_boost)
                    ts2, hits2 = taboo_score(me.taboo, s2)
                    if ts2 > 0.55:
                        s2 = apply_taboo_repairs(me, s2, hits2, topic)
                    s = ensure_concept_anchor(me, s2)
                    re_roll_msg = f"   ğŸ”„ (Re-roll via {mode_display})"
                else:
                    mode_display = f"{mode.upper()}->{mode.upper()}"

                verdict = self.arb.judge(s, me.name)
                note_str = f" {verdict.note}" if verdict.note else ""
                hud = f"   ğŸ“Š [Mode:{mode_display:<15} | Fric:{friction:.2f}] (T:{verdict.tension:.2f} C:{verdict.coherence:.2f} N:{verdict.novelty:.2f}){note_str}"

                if re_roll_msg:
                    yield re_roll_msg
                yield f"\nğŸ—£ï¸ {me.name} â†’ {other.name}:\n\"{s}\""
                yield f"{hud} => {verdict.status}" if verdict.status != "CONTINUE" else hud

                self.arb.adapt(self.philos, verdict)

                if state_lock:
                    async with state_lock:
                        self.positions[me.name] = s
                else:
                    self.positions[me.name] = s

                if verdict.status == "MELTDOWN":
                    yield "\nğŸ›‘ [SYSTEM] ì—”íŠ¸ë¡œí”¼ ì„ê³„ì  ì´ˆê³¼. íŒŒêµ­(MELTDOWN)ìœ¼ë¡œ ì¸í•´ í† ë¡  ì¤‘ë‹¨."
                    return
                if verdict.status == "CONSENSUS":
                    yield "\nâœ… [SYSTEM] ê³µëª…(Resonance) ë°œìƒ. í•©ì˜ ë„ë‹¬."
                    return

                await asyncio.sleep(0.1)

# ============================================================
# [SECTION 2] The Server & UI
# ============================================================

app = FastAPI()

html = """
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Agora Interactive</title>
    <style>
        body { font-family: 'Courier New', monospace; background: #0d1117; color: #c9d1d9; margin: 0; padding: 20px; display: flex; flex-direction: column; height: 95vh; }
        h1 { color: #58a6ff; text-align: center; margin-bottom: 10px; font-size: 1.5rem; }
        #chat-container { flex: 1; border: 1px solid #30363d; border-radius: 6px; padding: 15px; overflow-y: auto; background: #161b22; margin-bottom: 15px; box-shadow: inset 0 0 10px #000; }
        .message { margin-bottom: 8px; line-height: 1.4; border-bottom: 1px solid #21262d; padding-bottom: 4px; white-space: pre-wrap; }
        .hud { color: #8b949e; font-size: 0.85em; }
        .system { color: #f0883e; font-weight: bold; }
        .speaker { color: #79c0ff; font-weight: bold; }
        .reroll { color: #d2a8ff; font-style: italic; }
        #input-area { display: flex; gap: 10px; flex-direction: column; }
        .input-row { display: flex; gap: 10px; }
        input { flex: 1; padding: 10px; border-radius: 6px; border: 1px solid #30363d; background: #0d1117; color: #c9d1d9; font-family: inherit; }
        button { padding: 10px 20px; border-radius: 6px; border: none; background: #238636; color: white; cursor: pointer; font-weight: bold; font-family: inherit; }
        button#stopBtn { background: #da3633; }
        button:disabled { background: #484f58; cursor: not-allowed; }
        button:hover:not(:disabled) { opacity: 0.9; }
        input:focus { outline: 2px solid #58a6ff; }
        ::-webkit-scrollbar { width: 10px; }
        ::-webkit-scrollbar-track { background: #0d1117; }
        ::-webkit-scrollbar-thumb { background: #30363d; border-radius: 5px; }
        ::-webkit-scrollbar-thumb:hover { background: #58a6ff; }
    </style>
</head>
<body>
    <h1>ğŸ›ï¸ Grand Philosophical Agora (Production Ready)</h1>
    <div id="chat-container">
        <div class="message system">SYSTEM: ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. ì£¼ì œì™€ ì´ˆê¸° ì…ì¥ì„ ì…ë ¥í•˜ì—¬ í† ë¡ ì„ ì‹œì‘í•˜ì„¸ìš”.</div>
    </div>
    <div id="input-area">
        <div class="input-row">
            <input type="text" id="topicInput" placeholder="ì£¼ì œ: (ì˜ˆ: ì •ì˜ë€ ë¬´ì—‡ì¸ê°€?)" />
        </div>
        <div class="input-row">
            <input type="text" id="userClaimInput" placeholder="ë‚˜ì˜ ì£¼ì¥ / ê°œì… (Enterë¡œ ì „ì†¡)" />
            <button id="startBtn" onclick="sendAction('start')">í† ë¡  ì‹œì‘</button>
            <button id="stopBtn" onclick="sendAction('stop')" disabled>ì¤‘ë‹¨</button>
        </div>
    </div>

    <script>
        let ws;
        const chat = document.getElementById("chat-container");
        const topicInput = document.getElementById("topicInput");
        const claimInput = document.getElementById("userClaimInput");
        const startBtn = document.getElementById("startBtn");
        const stopBtn = document.getElementById("stopBtn");

        function connectWS() {
            const scheme = (location.protocol === "https:") ? "wss://" : "ws://";
            ws = new WebSocket(scheme + window.location.host + "/ws");

            ws.onopen = function() {
                const msg = document.createElement("div");
                msg.className = "message system";
                msg.innerText = "SYSTEM: ì„œë²„ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.";
                chat.appendChild(msg);

                // Reset UI State on Reconnect
                startBtn.disabled = false;
                stopBtn.disabled = true;
                startBtn.innerText = "í† ë¡  ì‹œì‘";
            };

            ws.onmessage = function(event) {
                const msg = document.createElement("div");
                msg.className = "message";
                let text = event.data;

                if (text.includes("ğŸ“Š")) msg.className += " hud";
                else if (text.includes("SYSTEM") || text.includes("ê°œíšŒì‚¬")) msg.className += " system";
                else if (text.includes("ğŸ”„")) msg.className += " reroll";
                else if (text.includes("ğŸ—£ï¸")) msg.className += " speaker";

                msg.innerText = text;
                chat.appendChild(msg);
                chat.scrollTop = chat.scrollHeight;

                if (text.includes("í† ë¡  ì¤‘ë‹¨") || text.includes("í•©ì˜ ë„ë‹¬") || text.includes("í† ë¡ ì´ ì¢…ë£Œ") || text.includes("í† ë¡ ì„ ì¢…ë£Œí•©ë‹ˆë‹¤")) {
                    startBtn.disabled = false;
                    stopBtn.disabled = true;
                    startBtn.innerText = "ìƒˆ í† ë¡  ì‹œì‘";
                }
            };

            ws.onclose = function() {
                const msg = document.createElement("div");
                msg.className = "message system";
                msg.innerText = "SYSTEM: ì—°ê²°ì´ ëŠì–´ì¡ŒìŠµë‹ˆë‹¤. ì¬ì—°ê²° ì‹œë„ ì¤‘...";
                chat.appendChild(msg);
                setTimeout(connectWS, 1000);
            };
        }

        connectWS();

        function sendAction(type) {
            if (!ws || ws.readyState !== WebSocket.OPEN) return;

            if (type === 'start') {
                const topic = topicInput.value.trim();
                const userClaim = claimInput.value.trim();
                if (!topic) { alert("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."); return; }

                startBtn.disabled = true;
                stopBtn.disabled = false;
                startBtn.innerText = "ì§„í–‰ ì¤‘...";
                chat.innerHTML = "";
                ws.send(JSON.stringify({ type: 'start', topic: topic, user_claim: userClaim }));
                claimInput.value = "";
                claimInput.placeholder = "í† ë¡  ì¤‘ ì–¸ì œë“ ì§€ ê°œì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤...";
            }
            else if (type === 'update') {
                if (!startBtn.disabled) return;
                const userClaim = claimInput.value.trim();
                if (!userClaim) return;
                ws.send(JSON.stringify({ type: 'update', text: userClaim }));
                claimInput.value = "";
            }
            else if (type === 'stop') {
                ws.send(JSON.stringify({ type: 'stop' }));
            }
        }

        // IME-Safe Key Binding
        claimInput.addEventListener("keydown", (e) => {
            if (e.key === "Enter" && !e.isComposing) {
                e.preventDefault();
                if (!startBtn.disabled) sendAction('start');
                else sendAction('update');
            }
        });
    </script>
</body>
</html>
"""

@app.get("/")
async def get():
    return HTMLResponse(html)

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()

    agora_instance: Optional[Agora] = None
    simulation_task: Optional[asyncio.Task] = None
    send_lock = asyncio.Lock()
    state_lock = asyncio.Lock()
    stop_event = asyncio.Event()  # For internal loop breaking
    server_state = "IDLE"  # IDLE, RUNNING

    async def cancel_task_safely():
        nonlocal simulation_task
        if simulation_task and not simulation_task.done():
            simulation_task.cancel()
            try:
                await simulation_task
            except asyncio.CancelledError:
                pass
        simulation_task = None

    async def safe_send(msg: str):
        nonlocal simulation_task
        try:
            async with send_lock:
                await websocket.send_text(msg)
        except:
            # [Zombie Killer+] Trigger stop & cancel if socket fails
            stop_event.set()
            if simulation_task and not simulation_task.done():
                simulation_task.cancel()

    def is_running() -> bool:
        return bool(agora_instance and simulation_task and (not simulation_task.done()) and server_state == "RUNNING")

    try:
        while True:
            data = await websocket.receive_text()
            try:
                payload = json.loads(data)
                action_type = payload.get("type", "start")
            except:
                continue

            if action_type == "start":
                # stop any previous simulation cleanly
                stop_event.set()
                await cancel_task_safely()
                stop_event.clear()

                server_state = "RUNNING"

                topic = payload.get("topic", "ì§„ë¦¬")
                user_claim = payload.get("user_claim", "") or ""

                cast = build_grand_cast()
                user_p = build_user_philosopher(user_claim)
                cast.insert(0, user_p)
                agora_instance = Agora(cast, seed=None)

                async with state_lock:
                    agora_instance.positions["ì‚¬ìš©ì"] = (
                        user_claim if user_claim else f"ì €ëŠ” '{topic}'ì— ëŒ€í•´, ìµœì†Œí•œ ë°˜ë°• ê°€ëŠ¥ì„±(ê²€ì¦/ë°˜ì¦)ì´ ìˆì–´ì•¼ ì§„ë¦¬ì— ê°€ê¹ë‹¤ê³  ë´…ë‹ˆë‹¤."
                    )

                async def run_sim():
                    nonlocal agora_instance, server_state
                    try:
                        async for line in agora_instance.run_async_generator(topic=topic, rounds=999, state_lock=state_lock, stop_event=stop_event):
                            if stop_event.is_set():
                                break
                            await safe_send(line)
                        if not stop_event.is_set():
                            await safe_send("\nğŸ [SYSTEM] í† ë¡ ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    except asyncio.CancelledError:
                        pass
                    finally:
                        agora_instance = None
                        server_state = "IDLE"

                simulation_task = asyncio.create_task(run_sim())

            elif action_type == "update":
                # [Server Guard] Strict State Check (+ task done check)
                if not is_running():
                    await safe_send("\nâš ï¸ [SYSTEM] ì‹¤í–‰ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤. ë¨¼ì € í† ë¡ ì„ ì‹œì‘í•˜ì„¸ìš”.")
                    continue

                new_claim = (payload.get("text", "") or "").strip()
                if not new_claim:
                    continue

                async with state_lock:
                    if agora_instance:
                        agora_instance.positions["ì‚¬ìš©ì"] = new_claim
                await safe_send(f"\nâœï¸ [SYSTEM] ì‚¬ìš©ì ì…ì¥ ì—…ë°ì´íŠ¸ ë°˜ì˜: \"{new_claim[:60]}...\"")

            elif action_type == "stop":
                stop_event.set()
                await cancel_task_safely()

                agora_instance = None
                server_state = "IDLE"
                await safe_send("\nğŸ [SYSTEM] ì‚¬ìš©ìì— ì˜í•´ í† ë¡ ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")

    except WebSocketDisconnect:
        stop_event.set()
        await cancel_task_safely()
        agora_instance = None
        server_state = "IDLE"
        print("Client disconnected")
    except Exception as e:
        stop_event.set()
        await cancel_task_safely()
        agora_instance = None
        server_state = "IDLE"
        print(f"Error: {e}")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
