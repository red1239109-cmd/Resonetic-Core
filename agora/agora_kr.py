# SPDX-License-Identifier: MIT
# Copyright (C) 2026 red1239109-cmd
# ==============================================================================
# File: agora_final.py
# Project: The Grand Philosophical Agora (Doomsday Clock Edition)
# Version: 56.0 (Zero Leak / Runtime Fixed / Flood Proof / Final Seal)
#
# [Changelog v56.0]
# 1. FIX: Defined missing 'BIND_TICKET_IP' config (Prevents NameError crash).
# 2. OPS: Added 'ip_gc()' & 'IP_LAST_SEEN' update to '/ticket' endpoint (Fixes HTTP Leak).
# 3. SEC: '/ticket' endpoint now strictly enforces Origin in PROD (No Host fallback).
# 4. SEC: Refined Origin Check logic to be strictly safe by default.
# 5. BASE: Inherits all previous hardening (Stateless, HMAC, Queue Safety).
# ==============================================================================
from __future__ import annotations
from dataclasses import dataclass, field
from typing import Dict, List, Tuple, Optional, Set, Union
import random
import math
import re
import asyncio
import json
import hashlib
import time
import os
import secrets
import hmac
import base64
import ipaddress
import sys
from collections import defaultdict, deque
from urllib.parse import urlparse, parse_qs
# --- Server Imports ---
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse
import uvicorn
# ============================================================
# [SECTION 0] Configuration & Hardening
# ============================================================
def get_env_list(key, default):
    val = os.getenv(key, default)
    return [x.strip() for x in val.split(",") if x.strip()]
DEV_MODE = os.getenv("AGORA_DEV_MODE", "0").lower() in ("1", "true")
MASTER_SECRET = os.getenv("AGORA_SECRET_TOKEN", "")
# [SEC] Hard Stop on Missing Secret in Prod
if not DEV_MODE and (not MASTER_SECRET or MASTER_SECRET == "change_me_in_prod_please"):
    print("ğŸš¨ FATAL: AGORA_SECRET_TOKEN is missing or default in Production!")
    sys.exit(1)
if DEV_MODE and not MASTER_SECRET:
    MASTER_SECRET = "dev_secret_key_123"
    print(f"âš ï¸ WARN: Running in DEV_MODE with default secret.")
ALLOWED_ORIGINS = set(get_env_list("AGORA_ALLOWED_ORIGINS", "http://localhost:8000,http://127.0.0.1:8000"))
if DEV_MODE:
    ALLOWED_ORIGINS.add("null")
RAW_PROXIES = get_env_list("AGORA_TRUSTED_PROXIES", "127.0.0.1,::1")
TRUSTED_NETWORKS = []
for p in RAW_PROXIES:
    try:
        if "/" in p:
            TRUSTED_NETWORKS.append(ipaddress.ip_network(p, strict=False))
        else:
            ip = ipaddress.ip_address(p)
            TRUSTED_NETWORKS.append(ipaddress.ip_network(f"{p}/{ip.max_prefixlen}", strict=False))
    except ValueError:
        print(f"âš ï¸ WARN: Invalid Trusted Proxy Config: {p}")
# [CONF] Ticket IP Binding Option (Fixes NameError)
BIND_TICKET_IP = os.getenv("AGORA_TICKET_BIND_IP", "1").lower() in ("1", "true")
# [OPS] Limits
IP_TTL = 600.0
IP_MAX_TRACKING = 50000
GC_INTERVAL = 10.0
MAX_ROUNDS_PER_SESSION = 50
MAX_CONCURRENT_PER_IP = 5
TICKET_TTL = 60.0
TICKET_USAGE_WINDOW = 30.0
JTI_MAX_TRACKING = 20000
WINDOW_SIZE = 6
WARMUP_CAST_PASSES = 1
RE_ROLL_THRESHOLD = 0.25
RHETORIC_THRESHOLD = 0.75
# ============================================================
# [SECTION 1] The Engine (Unchanged)
# ============================================================
def clamp(x: float, lo: float, hi: float) -> float:
    return lo if x < lo else hi if x > hi else x
def softmax(xs: List[float], temp: float = 1.0) -> List[float]:
    if not xs: return []
    m = max(xs)
    exps = [math.exp((x - m) / max(1e-9, temp)) for x in xs]
    z = sum(exps) or 1.0
    return [e / z for e in exps]
def cosine_sim(a: Dict[str, float], b: Dict[str, float]) -> float:
    keys = set(a) | set(b)
    if not keys: return 0.0
    dot = sum(a.get(k, 0.0) * b.get(k, 0.0) for k in keys)
    na = math.sqrt(sum(a.get(k, 0.0) ** 2 for k in keys)) or 1.0
    nb = math.sqrt(sum(b.get(k, 0.0) ** 2 for k in keys)) or 1.0
    return dot / (na * nb)
def jaccard(a: Set[str], b: Set[str]) -> float:
    if not a and not b: return 1.0
    if not a or not b: return 0.0
    return len(a & b) / len(a | b)
# [CORE] Hybrid Tokenizer
CORE_EASTERN = "ë¦¬|ê¸°|ì¸|ì˜ˆ|ì˜|ì‹¬|ì„±|ê²½|ë„|ë²•|ì•…|ì„ "
TOKEN_RE = re.compile(r"[ê°€-í£A-Za-z]{2,}|(?:" + CORE_EASTERN + r")|[\u4e00-\u9fff]", re.UNICODE)
def tokenize(text: str) -> Set[str]:
    return set(TOKEN_RE.findall(text))
CONCEPT_SYNONYMS = {
    # Western / General
    "ì§„ë¦¬": {"ì§„ë¦¬", "ì°¸", "ì°¸ë¨", "ì‚¬ì‹¤", "ì •ë‹¹í™”", "ì¸ì‹"},
    "ì´ì„±": {"ì´ì„±", "í•©ë¦¬", "ë…¼ë¦¬", "ì¶”ë¡ ", "ì—°ì—­"},
    "ê²½í—˜": {"ê²½í—˜", "ê´€ì°°", "ì‚¬ë¡€", "ì‹¤í—˜"},
    "ë³´í¸": {"ë³´í¸", "í•„ì—°", "ì¼ë°˜", "ê·œë²”"},
    "ë„ë•": {"ë„ë•", "ì˜ë¬´", "ì •ì–¸", "ìœ¤ë¦¬", "ì¡´ì—„", "ì„ "},
    "ììœ ": {"ììœ ", "ììœ¨", "ì˜ì§€"},
    "ê¶Œë ¥": {"ê¶Œë ¥", "í˜", "ì§€ë°°", "ìœ„ê³„"},
    "ê°€ì¹˜": {"ê°€ì¹˜", "í‰ê°€", "ì„ ì•…", "ì˜ë¯¸"},
    "ì–¸ì–´": {"ì–¸ì–´", "ë§", "í‘œí˜„", "ë¬¸ë²•", "ì‚¬ìš©"},
    "ì¡´ì¬": {"ì¡´ì¬", "ì‹¤ì¬", "ì‹¤ì²´", "ì¡´ì¬ë¡ "},
    "í˜•ì´ìƒ": {"í˜•ì´ìƒ", "ì´ˆì›”", "ë³¸ì§ˆ", "ì´ë°ì•„"},
    "ì‚¬íšŒ": {"ì‚¬íšŒ", "ì œë„", "ê·œìœ¨", "ì •ì¹˜", "ê³µì "},
    "ì—­ì‚¬": {"ì—­ì‚¬", "ê³„ë³´", "ì‹œëŒ€", "ë°œì „"},
    "ì£¼ì²´": {"ì£¼ì²´", "ìì•„", "ì˜ì‹"},
    "ë°©ë²•": {"ë°©ë²•", "ë¹„íŒ", "ë¶„ì„", "ë³€ì¦", "í•´ì²´", "ê²€ì—´"},
    "ì •ì˜": {"ì •ì˜", "ê³µì •", "ë¶„ë°°", "í˜•í‰", "ê¶Œë¦¬", "ë²•"},
   
    # Eastern
    "ë¦¬": {"ë¦¬", "ç†", "ì²œë¦¬", "ì´ì¹˜", "ì›ë¦¬", "ì§ˆì„œ"},
    "ê¸°": {"ê¸°", "æ°£", "ê¸°ì§ˆ", "ê¸°ìš´", "ë¬¼ì§ˆ", "ê¸°í™”"},
    "ì¸": {"ì¸", "ä»", "ì–´ì§", "ì‚¬ë‘", "ì¸¡ì€"},
    "ì˜ˆ": {"ì˜ˆ", "ç¦®", "ì˜ˆì ˆ", "ê·œë²”", "ì˜ë¡€"},
    "ì˜": {"ì˜", "ç¾©", "ì˜ë¡œì›€", "ë§ˆë•…í•¨"},
    "ì‹¬": {"ì‹¬", "å¿ƒ", "ë§ˆìŒ", "ì‹¬ì„±", "ì •"},
    "ì„±": {"ì„±", "æ€§", "ë³¸ì„±", "ì¸ì„±", "ì²œì„±"},
    "ìˆ˜ì–‘": {"ìˆ˜ì–‘", "ä¿®é¤Š", "ê³µë¶€", "ì„±ì°°", "ì¡´ì–‘"},
    "ê²½(æ•¬)": {"æ•¬", "ê±°ê²½", "ê±°ê²½ê¶ë¦¬", "ê²½ê±´"},
    "ê²½ì„¸": {"ê²½ì„¸", "ç¶“ä¸–", "ì¹˜êµ­", "ê²½ë¥œ", "ì œë„ê°œí˜", "ëª©ë¯¼"},
    "ì‹¤í•™": {"ì‹¤í•™", "å¯¦å­¸", "ì‹¤ì‚¬", "ì‹¤ìš©", "ì‹¤ì‚¬êµ¬ì‹œ", "ì´ìš©í›„ìƒ"},
    "ê´€ê³„": {"ê´€ê³„", "ì‚¬ì´", "ìƒí˜¸", "ì—°ëŒ€", "ì—°ê²°", "ê³µë™"},
}
CONCEPT_PATTERNS = {}
for concept, syns in CONCEPT_SYNONYMS.items():
    sorted_syns = sorted(list(syns), key=len, reverse=True)
    pattern_str = "|".join(re.escape(s) for s in sorted_syns)
    CONCEPT_PATTERNS[concept] = re.compile(pattern_str)
def extract_concepts(text: str) -> Set[str]:
    out = set()
    for concept, pattern in CONCEPT_PATTERNS.items():
        if pattern.search(text):
            out.add(concept)
    return out
# [GRAPH] Fully Connected
PHILO_GRAPHS = {
    # Western
    "í”Œë¼í†¤": {"í˜•ì´ìƒ": {"ì§„ë¦¬", "ë³´í¸", "ì¡´ì¬"}, "ì§„ë¦¬": {"í˜•ì´ìƒ", "ë³´í¸", "ì´ì„±"}, "ë³´í¸": {"ì§„ë¦¬", "í˜•ì´ìƒ", "ì´ì„±"}},
    "ì•„ë¦¬ìŠ¤í† í…”ë ˆìŠ¤": {"ê²½í—˜": {"ì§„ë¦¬", "ì¡´ì¬", "ë°©ë²•"}, "ì¡´ì¬": {"ê²½í—˜", "ì§„ë¦¬", "ë°©ë²•"}, "ë°©ë²•": {"ê²½í—˜", "ì¡´ì¬", "ì§„ë¦¬"}},
    "ì¹¸íŠ¸": {"ì´ì„±": {"ë³´í¸", "ë„ë•", "ë°©ë²•"}, "ë³´í¸": {"ì´ì„±", "ë„ë•", "ììœ "}, "ììœ ": {"ë„ë•", "ë³´í¸"}, "ì£¼ì²´": {"ë°©ë²•", "ê²½í—˜"}, "ë°©ë²•": {"ì´ì„±", "ë³´í¸"}},
    "ë‹ˆì²´": {"ê¶Œë ¥": {"ê°€ì¹˜", "ì§„ë¦¬", "ì—­ì‚¬"}, "ê°€ì¹˜": {"ê¶Œë ¥", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ê¶Œë ¥", "ê°€ì¹˜"}, "ì—­ì‚¬": {"ê¶Œë ¥", "ê°€ì¹˜"}},
    "ì†Œí¬ë¼í…ŒìŠ¤": {"ë°©ë²•": {"ì§„ë¦¬", "ì£¼ì²´", "ì´ì„±"}, "ì£¼ì²´": {"ë°©ë²•", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ë°©ë²•", "ì´ì„±"}},
    "ë°ì¹´ë¥´íŠ¸": {"ì£¼ì²´": {"ì´ì„±", "ì§„ë¦¬"}, "ì´ì„±": {"ì£¼ì²´", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì£¼ì²´", "ì´ì„±"}},
    "í„": {"ê²½í—˜": {"ì§„ë¦¬", "ë°©ë²•"}, "ë°©ë²•": {"ê²½í—˜", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ê²½í—˜", "ë°©ë²•"}},
    "ìŠ¤í”¼ë…¸ì": {"ì¡´ì¬": {"ì´ì„±", "ë³´í¸", "ì§„ë¦¬"}, "ì´ì„±": {"ì¡´ì¬", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì¡´ì¬", "ë³´í¸"}},
    "ë¼ì´í”„ë‹ˆì¸ ": {"ì´ì„±": {"ë³´í¸", "ì§„ë¦¬", "í˜•ì´ìƒ"}, "í˜•ì´ìƒ": {"ì´ì„±", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì´ì„±", "ë³´í¸"}},
    "ë¡œí¬": {"ê²½í—˜": {"ì£¼ì²´", "ì§„ë¦¬", "ì‚¬íšŒ"}, "ì£¼ì²´": {"ê²½í—˜", "ì§„ë¦¬"}, "ì‚¬íšŒ": {"ê²½í—˜", "ì§„ë¦¬"}},
    "ë£¨ì†Œ": {"ì‚¬íšŒ": {"ììœ ", "ë„ë•", "ê°€ì¹˜"}, "ììœ ": {"ì‚¬íšŒ", "ë„ë•"}, "ë„ë•": {"ì‚¬íšŒ", "ììœ "}},
    "ë°€": {"ê°€ì¹˜": {"ë„ë•", "ì‚¬íšŒ", "ì§„ë¦¬"}, "ë„ë•": {"ê°€ì¹˜", "ì‚¬íšŒ"}, "ì‚¬íšŒ": {"ê°€ì¹˜", "ë„ë•"}},
    "ë§ˆë¥´í¬ìŠ¤": {"ì‚¬íšŒ": {"ì—­ì‚¬", "ê¶Œë ¥", "ê°€ì¹˜"}, "ì—­ì‚¬": {"ì‚¬íšŒ", "ê¶Œë ¥"}, "ê¶Œë ¥": {"ì‚¬íšŒ", "ì—­ì‚¬"}},
    "í—¤ê²”": {"ì—­ì‚¬": {"ë°©ë²•", "ì§„ë¦¬", "ì‚¬íšŒ"}, "ë°©ë²•": {"ì—­ì‚¬", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì—­ì‚¬", "ë°©ë²•"}},
    "ì‡¼íœí•˜ìš°ì–´": {"ê°€ì¹˜": {"ì¡´ì¬", "ì£¼ì²´"}, "ì£¼ì²´": {"ê°€ì¹˜", "ì¡´ì¬"}, "ì¡´ì¬": {"ì£¼ì²´", "ê°€ì¹˜"}},
    "í‚¤ë¥´ì¼€ê³ ë¥´": {"ì£¼ì²´": {"ê°€ì¹˜", "ë„ë•", "ì§„ë¦¬"}, "ê°€ì¹˜": {"ì£¼ì²´", "ë„ë•"}, "ì§„ë¦¬": {"ì£¼ì²´", "ê°€ì¹˜"}},
    "ë¹„íŠ¸ê²ìŠˆíƒ€ì¸": {"ì–¸ì–´": {"ë°©ë²•", "ì§„ë¦¬"}, "ë°©ë²•": {"ì–¸ì–´", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì–¸ì–´", "ë°©ë²•"}},
    "í•˜ì´ë°ê±°": {"ì¡´ì¬": {"ì£¼ì²´", "ì§„ë¦¬"}, "ì£¼ì²´": {"ì¡´ì¬", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì¡´ì¬", "ì£¼ì²´"}},
    "ì‚¬ë¥´íŠ¸ë¥´": {"ììœ ": {"ì£¼ì²´", "ê°€ì¹˜", "ë„ë•"}, "ì£¼ì²´": {"ììœ ", "ê°€ì¹˜"}, "ê°€ì¹˜": {"ììœ ", "ì£¼ì²´"}},
    "í‘¸ì½”": {"ì‚¬íšŒ": {"ê¶Œë ¥", "ì§„ë¦¬", "ì—­ì‚¬"}, "ê¶Œë ¥": {"ì‚¬íšŒ", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì‚¬íšŒ", "ê¶Œë ¥"}},
    "ì•„ë ŒíŠ¸": {"ì‚¬íšŒ": {"ì§„ë¦¬", "ì—­ì‚¬", "ê°€ì¹˜"}, "ê°€ì¹˜": {"ì‚¬íšŒ", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ì‚¬íšŒ", "ê°€ì¹˜"}},
    "í¬í¼": {"ë°©ë²•": {"ê²½í—˜", "ì§„ë¦¬"}, "ê²½í—˜": {"ë°©ë²•", "ì§„ë¦¬"}, "ì§„ë¦¬": {"ë°©ë²•", "ê²½í—˜"}},
    "ë¡¤ìŠ¤": {"ë„ë•": {"ì‚¬íšŒ", "ììœ ", "ë³´í¸"}, "ì‚¬íšŒ": {"ë„ë•", "ë³´í¸"}, "ë³´í¸": {"ë„ë•", "ì‚¬íšŒ"}},
   
    # Eastern
    "ì´í™©": {
        "ë¦¬": {"ì„±", "ì‹¬", "ìˆ˜ì–‘"}, "ì‹¬": {"ì„±", "ìˆ˜ì–‘", "ì¸"}, "ì„±": {"ë¦¬", "ìˆ˜ì–‘"}, "ìˆ˜ì–‘": {"ê²½(æ•¬)", "ì˜ˆ", "ì‹¬"},
        "ì˜ˆ": {"ì¸", "ìˆ˜ì–‘", "ê´€ê³„"}, "ì¸": {"ì‹¬", "ì˜ˆ", "ê´€ê³„"}, "ê²½(æ•¬)": {"ìˆ˜ì–‘", "ì‹¬"}, "ê´€ê³„": {"ì¸", "ì˜ˆ"}
    },
    "ì´ì´": {
        "ê¸°": {"ì‹¬", "ìˆ˜ì–‘", "ê²½ì„¸"}, "ì‹¬": {"ê¸°", "ìˆ˜ì–‘"}, "ìˆ˜ì–‘": {"ê¸°", "ì˜ˆ", "ê²½ì„¸"}, "ê²½ì„¸": {"ìˆ˜ì–‘", "ì˜", "ì‚¬íšŒ", "ê´€ê³„"},
        "ì˜ˆ": {"ìˆ˜ì–‘", "ì‚¬íšŒ"}, "ì˜": {"ê²½ì„¸", "ì‚¬íšŒ"}, "ê´€ê³„": {"ê²½ì„¸", "ì‚¬íšŒ"}
    },
    "ì •ì•½ìš©": {
        "ê²½ì„¸": {"ì˜", "ì‚¬íšŒ", "ì •ì˜", "ê´€ê³„"}, "ì‚¬íšŒ": {"ê²½ì„¸", "ì •ì˜", "ê¶Œë ¥"}, "ì •ì˜": {"ê²½ì„¸", "ì‚¬íšŒ", "ì˜"}, "ì˜": {"ì •ì˜", "ê²½ì„¸"},
        "ì‹¤í•™": {"ê²½ì„¸", "ê²½í—˜", "ë°©ë²•"}, "ê´€ê³„": {"ê²½ì„¸", "ì •ì˜"}
    },
}
def pick_target_concept(topic: str, other_claim: str, rng: random.Random, fallback: str = "ì§„ë¦¬") -> str:
    tc = sorted(list(extract_concepts(topic)))
    if tc:
        h = int(hashlib.sha256(topic.encode('utf-8')).hexdigest(), 16)
        return tc[h % len(tc)]
    oc = sorted(list(extract_concepts(other_claim)))
    if oc: return rng.choice(oc)
    return fallback
def concept_graph_score(philo: str, text: str) -> float:
    cset = extract_concepts(text)
    g = PHILO_GRAPHS.get(philo, {})
    if not cset: return 0.0
    if g:
        nodes = set(g.keys())
        denom = max(2, min(len(nodes), len(cset)))
        coverage = len(cset & nodes) / denom
    else:
        coverage = min(1.0, len(cset) / 4)
    pairs = 0
    hits = 0
    cl = list(cset)
    for i in range(len(cl)):
        for j in range(i + 1, len(cl)):
            a, b = cl[i], cl[j]
            pairs += 1
            if g and (b in g.get(a, set()) or a in g.get(b, set())):
                hits += 1
            elif not g:
                hits += 0.5
    coherence = hits / max(1, pairs)
    return clamp(0.55 * coverage + 0.45 * coherence, 0.0, 1.0)
@dataclass(frozen=True)
class InferenceTaboo:
    name: str
    pattern: re.Pattern
    penalty: float
    explanation: str
    repair_hint: str
def taboo_score(taboo_rules: Union[List[InferenceTaboo], InferenceTaboo, None], text: str) -> Tuple[float, List[InferenceTaboo]]:
    if taboo_rules is None: taboo_rules = []
    if isinstance(taboo_rules, InferenceTaboo): taboo_rules = [taboo_rules]
    s = 0.0
    hits: List[InferenceTaboo] = []
    for r in taboo_rules:
        if r.pattern.search(text):
            s += r.penalty
            hits.append(r)
    return clamp(s, 0.0, 1.0), hits
TABOOS = {
    "kant_empirical_jump": InferenceTaboo("ê²½í—˜â†’ë³´í¸ ì í”„", re.compile(r"(ê²½í—˜|ê´€ì°°|ì‚¬ë¡€).{0,80}(ê·¸ë˜ì„œ|ë”°ë¼ì„œ).{0,80}(ë³´í¸|í•„ì—°|ê·œë²”|ì˜ë¬´)", re.UNICODE), 0.65, "ê²½í—˜ ë„ì•½", "ê²½í—˜ ëŒ€ì‹  'ê°€ëŠ¥ì¡°ê±´'ì„ ìš”êµ¬í•˜ë¼."),
    "kant_ends_justify": InferenceTaboo("ëª©ì ì´ ìˆ˜ë‹¨ ì •ë‹¹í™”", re.compile(r"(ëª©ì |ê²°ê³¼).{0,80}(ìˆ˜ë‹¨).{0,80}(ì •ë‹¹í™”|í•©ë¦¬í™”)", re.UNICODE), 0.75, "ì¡´ì—„ ì¶©ëŒ", "ìˆ˜ë‹¨-ëª©ì  ë…¼ì¦ì„ ì¤‘ë‹¨í•˜ê³  'ì¡´ì—„' ì œì•½ì„ ì‚½ì…í•˜ë¼."),
    "nietzsche_universal_morals": InferenceTaboo("ë³´í¸ ë„ë• ë‹¨ì–¸", re.compile(r"(ë³´í¸|ì ˆëŒ€).{0,80}(ë„ë•|ìœ¤ë¦¬|ì„ |ì•…|ë²•ì¹™)", re.UNICODE), 0.70, "ë³´í¸ ë„ë• ì˜ì‹¬", "'ëˆ„ê°€ ì´ë“ì„ ë³´ëŠ”ê°€'ë¡œ ê³„ë³´í•™ì  ì „í™˜ì„ ìˆ˜í–‰í•˜ë¼."),
    "nietzsche_truth_worship": InferenceTaboo("ì§„ë¦¬ ìˆ­ë°°", re.compile(r"(ì§„ë¦¬).{0,80}(ìµœê³ |ì‹ ì„±|ì ˆëŒ€|ìˆ­ë°°)", re.UNICODE), 0.55, "ì§„ë¦¬ ê°€ì¹˜ ì‹¬ë¬¸", "'ì§„ë¦¬ê°€ ì™œ ì„ ì¸ê°€'ë¥¼ ë¬»ëŠ” ê°€ì¹˜ì „ë„ ì§ˆë¬¸ì„ ì‚½ì…í•˜ë¼."),
    "hume_necessary_causation": InferenceTaboo("í•„ì—° ì¸ê³¼ ë‹¨ì–¸", re.compile(r"(ì›ì¸|ì¸ê³¼).{0,80}(ë°˜ë“œì‹œ|í•„ì—°|ì ˆëŒ€)", re.UNICODE), 0.65, "í•„ì—°ì„± íšŒì˜", "'ìŠµê´€/ê¸°ëŒ€'ë¡œ ì„¤ëª…ì„ í™˜ì›í•˜ë¼."),
    "witt_metaphysics_assert": InferenceTaboo("í˜•ì´ìƒí•™ ë‹¨ì–¸", re.compile(r"(ì´ë°ì•„|ì´ˆì›”|ë³¸ì§ˆ).{0,80}(ì¡´ì¬í•œë‹¤|ì‹¤ì¬í•œë‹¤|í™•ì‹¤í•˜ë‹¤)", re.UNICODE), 0.70, "ì–¸ì–´ í•œê³„ ì´ˆê³¼", "'ì–¸ì–´ ì‚¬ìš© ê·œì¹™'ìœ¼ë¡œ ì „í™˜í•˜ë¼."),
    "foucault_truth_neutral": InferenceTaboo("ì§„ë¦¬ ì¤‘ë¦½ì„±", re.compile(r"(ì§„ë¦¬).{0,80}(ì¤‘ë¦½|ìˆœìˆ˜|ë¬´ê´€)", re.UNICODE), 0.70, "ê¶Œë ¥-ì§€ì‹ ë§ê°", "'ì œë„/ê·œìœ¨/ì •ìƒí™”'ë¥¼ ë„£ì–´ ê¶Œë ¥ í”„ë ˆì„ìœ¼ë¡œ ì „í™˜í•˜ë¼."),
}
@dataclass
class Lexicon:
    core: List[str]
    evidentials: List[str]
    hedges: List[str]
    intensifiers: List[str]
    metaphors: List[str]
    taboo_softeners: List[str]
@dataclass
class ReasoningOps:
    ops: List[str]
@dataclass
class StyleProfile:
    rhetoric_bias: float
    justification_bias: float
    interrogation_bias: float
    poetic_bias: float
@dataclass
class Philosopher:
    name: str
    era: str
    truth_vector: Dict[str, float]
    lexicon: Lexicon
    reasoning: ReasoningOps
    taboo: List[InferenceTaboo]
    style: StyleProfile
    concept_explanation: Dict[str, str] = field(default_factory=dict)
    phase: Dict[str, float] = field(default_factory=lambda: {"open": 0.5, "attack": 0.5, "synthesize": 0.5})
@dataclass
class ArgGraph:
    claim: str = ""
    warrant: str = ""
    attack: str = ""
    constraint: str = ""
    synthesis: str = ""
def pick(xs: List[str], rng: random.Random) -> str:
    return rng.choice(xs) if xs else ""
def tension_to_register(t: float) -> str:
    return "low" if t < 0.33 else "mid" if t < 0.66 else "high"
# --- Ops ---
def op_define_split(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    w = pick(p.lexicon.evidentials, rng) or "ìš°ì„ "
    g.claim = f"{w} '{tgt}'ë¥¼ ë§í•  ë•Œ, ìš°ë¦¬ëŠ” 'ì‚¬ì‹¤'ê³¼ 'ì •ë‹¹í™”'ë¥¼ ì„ì–´ ë§í•©ë‹ˆë‹¤."
    g.warrant = "ê°œë…ì´ íë¦¬ë©´ ë…¼ìŸì€ ë§ì˜ ë¯¸ë„ëŸ¬ì§ì´ ë©ë‹ˆë‹¤."
def op_condition_censor(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¥¼ íŒë‹¨í•œë‹¤ëŠ” ë§ ìì²´ê°€ ì„±ë¦½í•˜ë ¤ë©´, ë¬´ì—‡ì´ ê·¸ê²ƒì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆê¹Œ?"
    g.warrant = "ê²½í—˜ë§Œìœ¼ë¡œëŠ” ë³´í¸ íƒ€ë‹¹ì„±ì„ ë³´ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    g.constraint = "ë”°ë¼ì„œ ê°€ëŠ¥í•œ ì¡°ê±´ì„ ë¨¼ì € ì„¸ì›Œì•¼ í•©ë‹ˆë‹¤."
def op_empirical_classify(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¼ê³  ë¶ˆë¦¬ëŠ” ì‚¬ë¡€ë“¤ì„ ëª¨ì•„ë´…ì‹œë‹¤: ê³¼í•™ì˜ ê²€ì¦, ë²•ì •ì˜ ì¦ëª…, ì¼ìƒì˜ ì‹ ë¢°."
    g.warrant = "ì‘ë™ ë°©ì‹ì´ ë‹¤ë¥¸ ê²ƒë“¤ì„ í•˜ë‚˜ë¡œ ë­‰ì¹˜ë©´ ì„¤ëª…ì´ ë¬´ë„ˆì§‘ë‹ˆë‹¤."
    g.constraint = "ë¶„ë¥˜ì™€ ì›ì¸ ë¶„ì„ì´ ë¨¼ì €ì…ë‹ˆë‹¤."
def op_reductio(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.attack = f"ì¢‹ìŠµë‹ˆë‹¤. ë§Œì•½ '{tgt}'ê°€ ì ˆëŒ€ì ì´ë¼ ê°€ì •í•©ì‹œë‹¤. ê·¸ëŸ¬ë©´ ì°¸ê³¼ ê±°ì§“ì˜ êµ¬ë¶„ ìì²´ê°€ ë¶•ê´´í•©ë‹ˆë‹¤."
    g.warrant = "êµ¬ë¶„ì´ ë¶•ê´´í•˜ë©´ ì£¼ì¥ë„ ìŠ¤ìŠ¤ë¡œì˜ ë°œíŒì„ ìƒìŠµë‹ˆë‹¤."
def op_genealogy_expose(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = rng.choice([
        f"'{tgt}'ëŠ” ìˆœìˆ˜í•œ ì–¼êµ´ì„ í•˜ê³  ë“±ì¥í•˜ì§€ë§Œ, ì—­ì‚¬ì ìœ¼ë¡œëŠ” ëˆ„êµ°ê°€ì˜ ì†ì— ë“¤ë¦° ë„êµ¬ì˜€ë‹¤.",
        f"'{tgt}'ë¼ëŠ” ë§ì´ ë“±ì¥í•˜ëŠ” ìˆœê°„, ì´ë¯¸ ëˆ„êµ°ê°€ì˜ ê¸°ì¤€ì´ ìŠ¹ë¦¬í•œ ê²ƒì´ë‹¤.",
        f"'{tgt}'ë¥¼ ë§í•˜ëŠ” ë°©ì‹ ìì²´ê°€ í˜ì˜ ë°°ì¹˜ë¥¼ ë“œëŸ¬ë‚¸ë‹¤.",
    ])
    g.attack = rng.choice([
        "ëˆ„ê°€ ê·¸ê²ƒì„ ë§í•  ê¶Œë¦¬ë¥¼ ë…ì í–ˆëŠ”ê°€?",
        "ê·¸ ë§ì´ ë¬´ì—‡ì„ ì •ìƒìœ¼ë¡œ ë§Œë“¤ê³  ë¬´ì—‡ì„ ë¹„ì •ìƒìœ¼ë¡œ ë°€ì–´ëƒˆëŠ”ê°€?",
        "ê·¸ ë‹´ë¡ ì´ ëˆ„êµ¬ë¥¼ â€˜ê°•ìâ€™ë¡œ, ëˆ„êµ¬ë¥¼ â€˜ì•½ìâ€™ë¡œ ë°°ì¹˜í–ˆëŠ”ê°€?",
    ])
    g.warrant = "ê³„ë³´ë¥¼ ë”°ë¼ê°€ë©´, â€˜ì°¸â€™ì€ ì¢…ì¢… ê°€ì¹˜ì™€ ê¶Œë ¥ì˜ ëƒ„ìƒˆë¥¼ í’ê¸´ë‹¤."
def op_value_invert(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = rng.choice([
        f"ì™œ '{tgt}'ê°€ ì„ ì´ë¼ëŠ” ì „ì œê°€ ìë™ìœ¼ë¡œ í†µê³¼í•˜ëŠ”ê°€?",
        f"'{tgt}'ë¥¼ ìˆ­ë°°í•˜ëŠ” ìë“¤ì€ ëŒ€ì²´ ë¬´ì—‡ì„ ë‘ë ¤ì›Œí•˜ëŠ”ê°€?",
        f"'{tgt}'ê°€ ì‚¶ì„ ê°•í™”í•œë‹¤ëŠ” ì¦ê±°ê°€ ìˆëŠ”ê°€â€”ì•„ë‹ˆë©´ ì‚¶ì„ ë§ˆë¹„ì‹œí‚¤ëŠ”ê°€?",
    ])
    g.warrant = "ê°€ì¹˜ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ë’¤ì§‘ì–´ ì ê²€í•˜ì§€ ì•Šìœ¼ë©´, â€˜ì§„ë¦¬â€™ëŠ” ìš°ìƒì´ ëœë‹¤."
    g.attack = "ë‚˜ëŠ” ìš°ìƒì„ ë¶€ìˆ˜ëŠ” ìª½ì„ íƒí•œë‹¤."
def op_language_therapy(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"ì—¬ê¸°ì„œ í˜¼ë€ì€ '{tgt}'ë¼ëŠ” ë‹¨ì–´ì˜ ì‚¬ìš© ê·œì¹™ì—ì„œ ë¹„ë¡¯ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    g.warrant = "ë§ì˜ ì“°ì„ì„ ì •ë¦¬í•˜ë©´, ë¬¸ì œì˜ ì ˆë°˜ì€ ì‚¬ë¼ì§‘ë‹ˆë‹¤."
    g.constraint = "í˜•ì´ìƒí•™ì  ë‹¨ì–¸ ëŒ€ì‹  ì‚¬ìš© ê·œì¹™ì„ ë³´ì„¸ìš”."
def op_power_knowledge(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = "ì§„ë¦¬ëŠ” ì§€ì‹ì˜ í˜•íƒœë¥¼ ë ì§€ë§Œ, ì§€ì‹ì€ ì œë„ì™€ ê·œìœ¨ê³¼ ì—°ê²°ë©ë‹ˆë‹¤."
    g.attack = f"'{tgt}' ë‹´ë¡ ì´ ë¬´ì—‡ì„ ì •ìƒí™”í•˜ê³  ë¬´ì—‡ì„ ë°°ì œí•˜ëŠ”ì§€ ë³´ì§€ ì•Šìœ¼ë©´ í•µì‹¬ì„ ë†“ì¹©ë‹ˆë‹¤."
    g.warrant = "ê¶Œë ¥-ì§€ì‹ ì¥ì¹˜ê°€ 'ì°¸'ì˜ ì¡°ê±´ì„ ë§Œë“­ë‹ˆë‹¤."
def op_public_world(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ëŠ” ê°œì¸ ë¨¸ë¦¿ì†ì—ë§Œ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ê³µì  ì„¸ê³„ì—ì„œ ë§ê³¼ í–‰ìœ„ë¡œ ë“œëŸ¬ë‚©ë‹ˆë‹¤."
    g.warrant = "ì§„ë¦¬ëŠ” ì„¸ê³„-ê³µìœ ì™€ ì±…ì„ì˜ ë¬¸ì œì…ë‹ˆë‹¤."
    g.synthesis = "ê·¸ë˜ì„œ ì§„ë¦¬ ë…¼ìŸì€ ì •ì¹˜ì Â·ìœ¤ë¦¬ì  ì°¨ì›ì„ í”¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
def op_elenchus(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¥¼ ì•ˆë‹¤ê³  ë§í•˜ëŠ”êµ°. ê·¸ë ‡ë‹¤ë©´ '{tgt}'ë¥¼ ì´ë£¨ëŠ” ìµœì†Œ ì¡°ê±´ í•˜ë‚˜ë§Œ ë§í•´ë³´ê²Œ."
    g.attack = "ê·¸ ì¡°ê±´ì´ í”ë“¤ë¦¬ë©´, ë„ˆì˜ 'ì•ˆë‹¤'ëŠ” ë§ë„ ê°™ì´ í”ë“¤ë¦°ë‹¤."
    g.warrant = "ì •ì˜ ì—†ì´ í™•ì‹ ë§Œ ë‚¨ìœ¼ë©´, ìš°ë¦¬ëŠ” ë§ì— ì†ëŠ”ë‹¤."
def op_methodic_doubt(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"ë‚˜ëŠ” '{tgt}'ì— ëŒ€í•´, ì˜ì‹¬ ê°€ëŠ¥í•œ ê²ƒì€ ì „ë¶€ ì˜ì‹¬í•´ë³´ê² ë‹¤."
    g.warrant = "ì˜ì‹¬ì„ í†µê³¼í•œ ê²ƒë§Œì´ í™•ì‹¤ì„±ì˜ ìê²©ì„ ì–»ëŠ”ë‹¤."
    g.constraint = "ê·¸ëŸ¬ë‹ˆ ë¨¼ì € ì˜ì‹¬ì— ê²¬ë””ëŠ” í† ëŒ€ë¥¼ ì œì‹œí•˜ë¼."
def op_hume_skeptic(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¥¼ ë§í•  ë•Œ, ìš°ë¦¬ëŠ” ë°˜ë³µì—ì„œ ìƒê¸´ ê¸°ëŒ€ë¥¼ 'í•„ì—°'ìœ¼ë¡œ ì°©ê°í•˜ê³¤ í•œë‹¤."
    g.warrant = "ì¸ê³¼Â·í•„ì—°Â·í™•ì‹¤ì€ ì¢…ì¢… ìŠµê´€ì˜ ë‹¤ë¥¸ ì´ë¦„ì´ë‹¤."
    g.attack = "ë„ˆì˜ í™•ì‹ ì€ ê²½í—˜ì˜ ë¹ˆí‹ˆì„ ë©”ìš°ëŠ” ìƒìƒì¼ ìˆ˜ ìˆë‹¤."
def op_dialectic(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ëŠ” ê³ ì •ëœ ì ì´ ì•„ë‹ˆë¼, ì¶©ëŒ ì†ì—ì„œ ì „ê°œë˜ëŠ” ê³¼ì •ì´ë‹¤."
    g.warrant = "í•œìª½ë§Œ ë¶™ë“¤ë©´ ëª¨ìˆœì´ ìŒ“ì´ê³ , ê·¸ ëª¨ìˆœì´ ë‹¤ìŒ êµ­ë©´ì„ ì—°ë‹¤."
    g.synthesis = "ê·¸ëŸ¬ë‹ˆ ë°˜ëŒ€í•­ì„ ì œê±°í•˜ì§€ ë§ê³ , ë” ë†’ì€ í†µì¼ë¡œ ë“¤ì–´ì˜¬ë ¤ë¼."
def op_pessimism_will(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ëŠ” ì´ì„±ì˜ ìŠ¹ë¦¬ê°€ ì•„ë‹ˆë¼, ì˜ì§€ê°€ ìê¸° ê³ í†µì„ í¬ì¥í•˜ëŠ” ë°©ì‹ì¼ ìˆ˜ ìˆë‹¤."
    g.warrant = "ì‚¶ì´ ë¨¼ì €ì´ê³ , ì´ì„±ì€ ê·¸ ë’¤ë¥¼ ë”°ë¼ ë¯¸í™”í•œë‹¤."
    g.attack = "ë„ˆì˜ ì§„ë¦¬ëŠ” ê³ í†µì„ ëœì–´ì£¼ëŠ” ì•½ì¸ê°€, í˜„ì‹¤ì„ ê°€ë¦¬ëŠ” ì•ˆê°œì¸ê°€?"
def op_subjective_truth(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ê°€ ê°ê´€ì  ê³µë¬¸ì„œì²˜ëŸ¼ ì¡´ì¬í•œë‹¤ëŠ” ë¯¿ìŒë¶€í„° ì˜ì‹¬í•˜ì."
    g.warrant = "ì¤‘ìš”í•œ ê²ƒì€ ë‚´ê°€ ê·¸ ì§„ë¦¬ì— ì–´ë–»ê²Œ â€˜ê±¸ë ¤ë“œëŠ”ê°€â€™ë‹¤."
    g.attack = "ë„ˆì˜ ì§„ë¦¬ëŠ” ì‚¶ì„ ë°”ê¾¸ëŠ”ê°€, ì•„ë‹ˆë©´ ë‚¨ì„ ì‹¬íŒí•˜ëŠ” ë„êµ¬ì¸ê°€?"
def op_being_unconceal(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¥¼ â€˜ì •í™•í•œ ëª…ì œâ€™ë¡œë§Œ ë³´ì§€ ë§ˆë¼. ì§„ë¦¬ëŠ” ë“œëŸ¬ë‚¨(ì•Œë ˆí…Œì´ì•„)ì´ë‹¤."
    g.warrant = "ë¬´ì—‡ì´ ìˆ¨ê²¨ì§€ê³  ë¬´ì—‡ì´ ë“œëŸ¬ë‚˜ëŠ”ì§€, ê·¸ êµ¬ì¡°ë¥¼ ë³´ë¼."
    g.constraint = "ë¨¼ì € â€˜ì¡´ì¬â€™ê°€ ì–´ë–»ê²Œ ì—´ë¦¬ëŠ”ì§€ ë¬¼ì–´ì•¼ í•œë‹¤."
def op_existential_choice(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¥¼ ì°¾ê² ë‹¤ëŠ” ë§ì€ ê²°êµ­ ì„ íƒì˜ ë¬¸ì œë‹¤."
    g.warrant = "ë„ˆëŠ” ì„ íƒí•˜ì§€ ì•Šì„ ììœ ë„ ì—†ë‹¤. ì¹¨ë¬µë„ í•˜ë‚˜ì˜ ì„ íƒì´ë‹¤."
    g.attack = "ë„ˆì˜ ì§„ë¦¬ëŠ” ì±…ì„ì„ ì§€ê²Œ ë§Œë“œëŠ”ê°€, ì±…ì„ì„ íšŒí”¼í•˜ê²Œ ë§Œë“œëŠ”ê°€?"
def op_marx_ideology(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ëŠ” ë¨¸ë¦¬ì—ì„œ ë–¨ì–´ì§„ ë³„ì´ ì•„ë‹ˆë‹¤. ìƒì‚°ê³¼ ì œë„ì˜ ë°”ë‹¥ì—ì„œ ë§Œë“¤ì–´ì§„ë‹¤."
    g.warrant = "ì§€ë°°ì  ì§„ë¦¬ëŠ” ì§€ë°°ì  ê´€ê³„ë¥¼ ì •ë‹¹í™”í•˜ëŠ” ê²½í–¥ì´ ìˆë‹¤."
    g.attack = "ëˆ„ê°€ ê·¸ ì§„ë¦¬ë¡œ ì´ë“ì„ ë³´ëŠ”ì§€ë¶€í„° ë³´ë¼."
def op_utilitarian(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¥¼ ë…¼í•  ë•Œ, ê²°ê³¼ì˜ íŒŒê¸‰ì„ ê³„ì‚°ì—ì„œ ì œì™¸í•  ìˆ˜ ì—†ë‹¤."
    g.warrant = "ê·œì¹™ì€ í–‰ë³µ/ê³ í†µì˜ ì´ëŸ‰ê³¼ ì—°ê²°ë  ë•Œ ì„¤ë“ë ¥ì„ ì–»ëŠ”ë‹¤."
    g.constraint = "ë”°ë¼ì„œ ì–´ë–¤ ë§ì´ ì‹¤ì œë¡œ ì–´ë–¤ í”¼í•´/ì´ë“ì„ ë§Œë“œëŠ”ì§€ ë³´ë¼."
def op_falsification(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ë¼ê³  ì£¼ì¥í•œë‹¤ë©´, ì–´ë–¤ ì¡°ê±´ì—ì„œ ê·¸ ì£¼ì¥ì´ ë°˜ë°•ë˜ëŠ”ì§€ ë¨¼ì € ë§í•´ì•¼ í•œë‹¤."
    g.warrant = "ë°˜ë°• ê°€ëŠ¥ì„±ì´ ì—†ëŠ” í™•ì‹ ì€ ì§€ì‹ì´ ì•„ë‹ˆë¼ ì‹ ë…ì´ë‹¤."
    g.attack = "ë„ˆì˜ ì§„ë¦¬ëŠ” ìœ„í—˜ì„ ê°ìˆ˜í•˜ëŠ”ê°€, ì•„ë‹ˆë©´ ë„ë§ì¹˜ê¸° ì‰¬ìš´ê°€?"
def op_original_position(p, topic, other, g, t, rng, target=""):
    tgt = target if target else topic
    g.claim = f"'{tgt}'ì˜ ê·œì¹™ì„ ì„¸ìš´ë‹¤ë©´, ë‚´ê°€ ëˆ„êµ¬ì¸ì§€ ëª¨ë¥´ëŠ” ìƒíƒœì—ì„œ ê·¸ ê·œì¹™ì„ ì„ íƒí•˜ê² ëŠ”ê°€?"
    g.warrant = "ê³µì •ì€ ìê¸° ì´ìµì„ ê°€ë¦¬ëŠ” ì¥ì¹˜ì—ì„œ ì‹œí—˜ëœë‹¤."
    g.constraint = "ê·¸ëŸ¬ë‹ˆ ëª¨ë‘ê°€ ë°›ì•„ë“¤ì¼ ìˆ˜ ìˆëŠ” ì¡°ê±´ì„ ë¨¼ì € ì„¸ì›Œë¼."
OPS = {
    "define_split": op_define_split,
    "condition_censor": op_condition_censor,
    "empirical_classify": op_empirical_classify,
    "reductio": op_reductio,
    "genealogy_expose": op_genealogy_expose,
    "value_invert": op_value_invert,
    "language_therapy": op_language_therapy,
    "power_knowledge": op_power_knowledge,
    "public_world": op_public_world,
    "elenchus": op_elenchus,
    "methodic_doubt": op_methodic_doubt,
    "hume_skeptic": op_hume_skeptic,
    "dialectic": op_dialectic,
    "pessimism_will": op_pessimism_will,
    "subjective_truth": op_subjective_truth,
    "being_unconceal": op_being_unconceal,
    "existential_choice": op_existential_choice,
    "marx_ideology": op_marx_ideology,
    "utilitarian": op_utilitarian,
    "falsification": op_falsification,
    "original_position": op_original_position,
}
# --- Helpers ---
def apply_taboo_repairs(p: Philosopher, text: str, hits: List[InferenceTaboo], topic: str, rng: random.Random) -> str:
    if not hits: return text
    repairs = []
    for h in hits[:2]:
        if "ê°€ëŠ¥ì¡°ê±´" in h.repair_hint: repairs.append("ì¤‘ìš”í•œ ê±´ 'ê°€ëŠ¥ ì¡°ê±´'ì…ë‹ˆë‹¤.")
        elif "ì¡´ì—„" in h.repair_hint: repairs.append("ì–´ë–¤ ëª©ì ë„ ì¡´ì—„ì„ í•´ì¹  ìˆœ ì—†ìŠµë‹ˆë‹¤.")
        elif "ê³„ë³´í•™" in h.repair_hint: repairs.append("ëˆ„ê°€ ì„ ì´ë¼ ë¶€ë¥´ë©° í˜ì„ ì–»ëŠ”ê°€?")
        elif "ê°€ì¹˜ì „ë„" in h.repair_hint: repairs.append("â€˜ì§„ë¦¬ê°€ ì™œ ì„ ì¸ê°€â€™ë¶€í„° ë‹¤ì‹œ ë¬»ì.")
        elif "ìŠµê´€" in h.repair_hint: repairs.append("'í•„ì—°'ì€ ë‹¨ì§€ ìŠµê´€ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif "ì–¸ì–´ ì‚¬ìš©" in h.repair_hint: repairs.append("ê·¸ ë‹¨ì–¸ì€ ì–¸ì–´ì˜ ì˜¤ìš©ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif "ê¶Œë ¥-ì§€ì‹" in h.repair_hint: repairs.append("ì§„ë¦¬ëŠ” ê¶Œë ¥ ì¥ì¹˜ì™€ ì–½í˜€ ìˆìŠµë‹ˆë‹¤.")
    soft = pick(p.lexicon.taboo_softeners, rng)
    add = (" " + soft + " " if soft else " ") + " ".join(repairs)
    return (text + add).strip()
# [UX] Anti-Repetition Cooldown for Anchors
LAST_ANCHOR_TIME = defaultdict(float)
def ensure_concept_anchor(p: Philosopher, text: str) -> str:
    cg = concept_graph_score(p.name, text)
    if cg >= 0.24: return text
   
    # [UX] Cooldown Check (Prevents anchor spam per philosopher)
    now = time.monotonic()
    if now - LAST_ANCHOR_TIME[p.name] < 15.0: # 15s Cooldown
        return text
       
    LAST_ANCHOR_TIME[p.name] = now
   
    anchors = {
        "ì¹¸íŠ¸": " ë³´í¸ íƒ€ë‹¹ì„±ì„ ìœ„í•´ì„  ê°€ëŠ¥ ì¡°ê±´ì„ ìš”êµ¬í•´ì•¼ í•©ë‹ˆë‹¤.",
        "ë‹ˆì²´": " ê²°êµ­ ê·¸ 'ì§„ë¦¬'ëŠ” ê°€ì¹˜ì˜ ê°€ë©´ì´ë‹¤!",
        "í”Œë¼í†¤": " ë³€í•˜ì§€ ì•ŠëŠ” ê¸°ì¤€ì´ ì—†ìœ¼ë©´ ì§„ë¦¬ëŠ” í©ì–´ì§‘ë‹ˆë‹¤.",
        "ì•„ë¦¬ìŠ¤í† í…”ë ˆìŠ¤": " ì‚¬ë¡€ì™€ ì›ì¸ ë¶„ì„ìœ¼ë¡œ ë§ì„ ì„¸ì›Œì•¼ í•©ë‹ˆë‹¤.",
        "ì†Œí¬ë¼í…ŒìŠ¤": " ë„ˆëŠ” ê·¸ê²ƒì„ ì§„ì •ìœ¼ë¡œ ì•„ëŠ”ê°€?",
        "ë°ì¹´ë¥´íŠ¸": " ë‚˜ëŠ” ìƒê°í•œë‹¤, ê³ ë¡œ ì¡´ì¬í•œë‹¤.",
        "ë§ˆë¥´í¬ìŠ¤": " ë¬¸ì œëŠ” í•´ì„ì´ ì•„ë‹ˆë¼ ë³€í˜ì´ë‹¤.",
        "ë¹„íŠ¸ê²ìŠˆíƒ€ì¸": " ë§í•  ìˆ˜ ì—†ëŠ” ê²ƒì—” ì¹¨ë¬µí•´ì•¼ í•©ë‹ˆë‹¤.",
        "ì´í™©": " ë§ˆë•…íˆ ê²½(æ•¬)ìœ¼ë¡œ ë§ˆìŒì„ ì£¼ì¬í•´ì•¼ í•©ë‹ˆë‹¤.",
        "ì´ì´": " ë•Œì— ë§ê²Œ ë³€í™”í•˜ëŠ” ê²ƒì´ ë„ë¦¬ì…ë‹ˆë‹¤.",
        "ì •ì•½ìš©": " ì‹¤ì²œ ì—†ëŠ” ì•ì€ í—›ëœ ê²ƒì…ë‹ˆë‹¤.",
    }
    return (text + anchors.get(p.name, "")).strip()
TOPIC_ANCHORS = {
    "ì‚¬íšŒ": [
        "ì—¬ê¸°ì„œ 'ì‚¬íšŒ'ëŠ” ê°œì¸ì˜ í•©ì´ ì•„ë‹ˆë¼, ê´€ê³„Â·ê·œì¹™Â·ì œë„ê°€ ì—®ì¸ êµ¬ì¡°ë¥¼ ëœ»í•©ë‹ˆë‹¤.",
        "'ì‚¬íšŒ'ë¥¼ ë¬»ëŠ”ë‹¤ë©´ ì œë„(ë²•/ê·œë²”)ì™€ ê¶Œë ¥, ì—°ëŒ€ê°€ ì–´ë–»ê²Œ ìƒê¸°ëŠ”ì§€ë¡œ ë‚´ë ¤ì™€ì•¼ í•©ë‹ˆë‹¤.",
    ],
    "ì •ì˜": [
        "ì—¬ê¸°ì„œ 'ì •ì˜'ëŠ” 'ì˜³ìŒ/ê³µì •/ì •ë‹¹í•œ ë¶„ë°°' ê°™ì€ ê·œë²” ê¸°ì¤€ì„ ëœ»í•©ë‹ˆë‹¤.",
        "'ì •ì˜'ëŠ” ë‹¨ìˆœí•œ ì •ì˜(Definition)ê°€ ì•„ë‹ˆë¼, ë¬´ì—‡ì´ ê³µì •í•œê°€ì˜ ê¸°ì¤€ ë¬¸ì œì…ë‹ˆë‹¤.",
    ],
    "ê´€ê³„": [
        "ì¸ê°„ì€ í™€ë¡œ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‚¬ì´(Inter)ì—ì„œ ì˜ë¯¸ê°€ ë°œìƒí•©ë‹ˆë‹¤.",
        "ë‚˜ì™€ ë„ˆì˜ ê´€ê³„ê°€ ê³§ ìœ¤ë¦¬ì˜ ì‹œì‘ì…ë‹ˆë‹¤.",
    ],
    "ìˆ˜ì–‘": [
        "ë§ˆìŒì„ ë‹¦ëŠ” ê²ƒì€ ê³§ ì„¸ìƒì„ ëŒ€í•˜ëŠ” íƒœë„ë¥¼ ë‹¦ëŠ” ê²ƒì…ë‹ˆë‹¤.",
        "ì•„ëŠ” ê²ƒë³´ë‹¤ í–‰í•˜ëŠ” ê²ƒì´ ì–´ë µìŠµë‹ˆë‹¤.",
    ],
    "ì˜ˆ": [
        "ì˜ˆ(ç¦®)ëŠ” ê²‰ì¹˜ë ˆê°€ ì•„ë‹ˆë¼, íƒ€ì¸ì„ ì¡´ì¤‘í•˜ëŠ” ë§ˆìŒì˜ í˜•ì‹ì…ë‹ˆë‹¤.",
        "ì§ˆì„œëŠ” ê°•ìš”ê°€ ì•„ë‹ˆë¼, ìë°œì ì¸ ì˜ˆ(ç¦®)ì—ì„œ ë‚˜ì˜µë‹ˆë‹¤.",
    ]
}
def inject_topic_anchor(topic: str, text: str, p_name: str, rng: random.Random, mode: str = "normal") -> str:
    prob = 0.35
    if mode == "opening": prob = 0.80
    elif mode == "reroll": prob = 0.90
   
    if "ì •ì˜" in topic and mode == "opening":
        prob = 1.0
    if rng.random() > prob: return text
   
    topic_concepts = extract_concepts(topic)
    for key, anchors in TOPIC_ANCHORS.items():
        if key in topic_concepts:
            add = rng.choice(anchors)
            if p_name == "ë‹ˆì²´":
                add = add.replace("ì…ë‹ˆë‹¤", "ì´ë‹¤").replace("í•©ë‹ˆë‹¤", "í•œë‹¤")
            return (text + " " + add).strip()
    return text
def build_arggraph(p: Philosopher, topic: str, other_claim: str, tension: float, mode: str, rng: random.Random, entropy_boost: float = 0.0) -> ArgGraph:
    g = ArgGraph()
    raw_ops = p.reasoning.ops
    unique_ops = list(dict.fromkeys(raw_ops))
    atk_bias = 0.9 + 0.8 * p.phase.get("attack", 0.5)
    syn_bias = 0.9 + 0.8 * p.phase.get("synthesize", 0.5)
    open_bias = 0.9 + 0.6 * p.phase.get("open", 0.5)
    reg = tension_to_register(tension)
    weights = []
    attack_ops = {"reductio", "genealogy_expose", "power_knowledge", "value_invert", "hume_skeptic", "pessimism_will", "marx_ideology", "elenchus"}
    syn_ops = {"public_world", "define_split", "dialectic", "utilitarian"}
    open_ops = {"define_split", "empirical_classify", "condition_censor", "language_therapy", "methodic_doubt", "being_unconceal", "original_position", "falsification"}
    for opn in unique_ops:
        w = 1.0
        if mode == "attack" and opn in attack_ops: w *= atk_bias
        if mode == "synthesize" and opn in syn_ops: w *= syn_bias
        if mode == "open" and opn in open_ops: w *= open_bias
        if reg == "high": w *= (1.0 + 0.6 * p.style.rhetoric_bias)
        elif reg == "low": w *= (1.0 + 0.6 * p.style.justification_bias)
        weights.append(w)
    probs = softmax(weights, temp=0.9 + entropy_boost)
    k = 3 if reg != "low" else 2
    if entropy_boost > 0.0 and len(unique_ops) >= 4:
        k += 1
    chosen: Set[str] = set()
    attempts = 0
    target_k = min(k, len(unique_ops))
    while len(chosen) < target_k and attempts < 20:
        attempts += 1
        r = rng.random()
        cum = 0.0
        for opn, pr in zip(unique_ops, probs):
            cum += pr
            if r <= cum:
                chosen.add(opn)
                break
    if len(chosen) < target_k:
        remaining = [op for op in unique_ops if op not in chosen]
        if remaining:
            chosen.update(rng.sample(remaining, min(len(remaining), target_k - len(chosen))))
    ordered_chosen = [op for op in unique_ops if op in chosen]
   
    fallback_target = "ì •ì˜" if "ì •ì˜" in topic else ("ì‚¬íšŒ" if "ì‚¬íšŒ" in topic else topic)
    target = pick_target_concept(topic, other_claim, rng, fallback=fallback_target)
   
    for opn in ordered_chosen:
        OPS[opn](p, topic, other_claim, g, tension, rng, target=target)
    return g
def linearize(p: Philosopher, g: ArgGraph, tension: float, rng: random.Random) -> str:
    reg = tension_to_register(tension)
    if reg == "low":
        lead = pick(p.lexicon.hedges, rng) or "ì•„ë§ˆë„"
    elif reg == "mid":
        lead = "ê·¸ëŸ¬ë‚˜"
    else:
        lead = pick(p.lexicon.intensifiers, rng) or "ë‹¨í˜¸íˆ"
    parts: List[str] = []
    if p.style.interrogation_bias > 0.65:
        parts.append(f"{lead}, ë¨¼ì € ë¬»ê² ìŠµë‹ˆë‹¤.")
    if reg == "high" and p.style.rhetoric_bias >= p.style.justification_bias:
        if g.attack: parts.append(g.attack)
        if g.claim: parts.append(g.claim)
        if g.warrant: parts.append(g.warrant)
        if g.constraint: parts.append(g.constraint)
        if g.synthesis: parts.append(g.synthesis)
    else:
        if g.claim: parts.append(f"{lead}, {g.claim}")
        if g.warrant: parts.append(g.warrant)
        if g.constraint: parts.append(g.constraint)
        if g.attack: parts.append(g.attack)
        if g.synthesis: parts.append(g.synthesis)
    if p.style.poetic_bias > 0.6 and p.lexicon.metaphors:
        parts.insert(0, pick(p.lexicon.metaphors, rng))
    text = " ".join([s.strip() for s in parts if s and s.strip()])
    if rng.random() < 0.25:
        core_word = pick(p.lexicon.core, rng)
        if core_word:
            text = f"({core_word}) {text}"
    if p.name == "ë‹ˆì²´":
        text = text.replace("í•©ë‹ˆë‹¤", "í•œë‹¤").replace("ì…ë‹ˆë‹¤", "ì´ë‹¤")
        if reg == "high":
            text = text.replace(".", "!")
    return text.strip()
@dataclass
class Verdict:
    status: str
    note: str
    tension: float
    coherence: float
    novelty: float
    is_warmup: bool = False
class Arbiter:
    def __init__(self, cast_size: int):
        self.t_hist: List[float] = []
        self.c_hist: List[float] = []
        self.n_hist: List[float] = []
        self.last: List[str] = []
        self.p_last: Dict[str, str] = {}
        self.warmup_turns = cast_size * WARMUP_CAST_PASSES
        self.window_size = WINDOW_SIZE
        self.turn_count = 0
        self.warmup_done = False
        self.calibration_snapshot = (0.0, 0.0, 0.0)
    def novelty_check(self, text: str, speaker: str) -> float:
        toks = tokenize(text)
        glob_n = 1.0
        if self.last:
            window = self.last[-self.window_size:]
            max_sim = max([jaccard(toks, tokenize(prev)) for prev in window], default=0.0)
            glob_n = clamp(1.0 - max_sim, 0.0, 1.0)
        pers_n = 1.0
        if speaker in self.p_last:
            prev_p = tokenize(self.p_last[speaker])
            pers_n = clamp(1.0 - jaccard(toks, prev_p), 0.0, 1.0)
        return (glob_n * 0.4) + (pers_n * 0.6)
    def judge(self, text: str, speaker: str) -> Verdict:
        t_raw = sum(1 for m in ["ë¶•ê´´", "í­ë¡œ", "ê²€ì—´", "ë°°ì œ", "ë„ì•½", "ìœ„ì„ ", "ì§€ë°°", "ê°€ë©´", "ìš°ìƒ", "ë…ì ", "íˆ¬ìŸ"] if m in text) + min(2, text.count("!") // 2)
        t = clamp(t_raw / 6.0, 0.0, 1.0)
        c_density = clamp(len(extract_concepts(text)) / 6.0, 0.0, 1.0)
        c = clamp(c_density, 0.0, 1.0)
        n = self.novelty_check(text, speaker)
        self.turn_count += 1
        self.t_hist.append(t)
        self.c_hist.append(c)
        self.n_hist.append(n)
       
        self.last.append(text)
        if len(self.last) > self.window_size * 5:
            self.last = self.last[-self.window_size * 2:]
        self.p_last[speaker] = text
        if not self.warmup_done:
            if self.turn_count < self.warmup_turns:
                return Verdict("CONTINUE", "(Warm-up)", t, c, n, is_warmup=True)
            elif self.turn_count == self.warmup_turns:
                self.calibration_snapshot = (t, c, n)
                self.warmup_done = True
                self.t_hist.clear()
                self.c_hist.clear()
                self.n_hist.clear()
                self.last.clear()
                self.p_last.clear()
                return Verdict("RESET", f"(Calibration Complete: ë³¸ í† ë¡  ì‹œì‘) [Snap: T{t:.2f}/C{c:.2f}/N{n:.2f}]", t, c, n, is_warmup=True)
        if len(self.t_hist) >= 5:
            if (sum(1 for x in self.t_hist[-5:] if x > 0.80) >= 4) and (sum(1 for y in self.c_hist[-5:] if y < 0.28) >= 3):
                return Verdict("MELTDOWN", "íŒŒêµ­ ì„ë°•.", t, c, n)
        if len(self.n_hist) >= 6:
            if sum(1 for x in self.n_hist[-6:] if x < 0.25) >= 5:
                return Verdict("DEADLOCK", "êµì°© ìƒíƒœ.", t, c, n)
        if len(self.t_hist) >= 6:
            th = self.t_hist
            ch = self.c_hist
            if th[-6] > 0.70 and th[-1] < 0.35 and ch[-1] > 0.45:
                return Verdict("CONSENSUS", "ê³µëª… ë°œìƒ.", t, c, n)
        return Verdict("CONTINUE", "", t, c, n)
    def adapt(self, philos: List[Philosopher], verdict: Verdict):
        if verdict.status == "RESET":
            (t, c, n) = self.calibration_snapshot
            for p in philos:
                p.phase["open"] = clamp(p.phase["open"] + 0.1 * n, 0.0, 1.0)
            return
        if verdict.is_warmup:
            return
        for p in philos:
            if verdict.status == "MELTDOWN":
                p.phase["attack"] = clamp(p.phase["attack"] - 0.15, 0.0, 1.0)
                p.phase["open"] = clamp(p.phase["open"] + 0.10, 0.0, 1.0)
                p.phase["synthesize"] = clamp(p.phase["synthesize"] + 0.10, 0.0, 1.0)
            elif verdict.status == "DEADLOCK":
                p.phase["open"] = clamp(p.phase["open"] + 0.15, 0.0, 1.0)
                p.phase["attack"] = clamp(p.phase["attack"] + 0.05, 0.0, 1.0)
            elif verdict.status == "CONSENSUS":
                p.phase["synthesize"] = clamp(p.phase["synthesize"] + 0.15, 0.0, 1.0)
                p.phase["attack"] = clamp(p.phase["attack"] - 0.10, 0.0, 1.0)
            else:
                for k in p.phase:
                    p.phase[k] = clamp(p.phase[k] * 0.98 + 0.01, 0.0, 1.0)
def build_user_philosopher(user_claim: str) -> Philosopher:
    cs = extract_concepts(user_claim or "")
    if not cs:
        cs = {"ì§„ë¦¬"}
    vec = {c: 1.0 for c in cs}
    soft_mix = ["ê·¸ëŸ°ë°", "í•˜ì§€ë§Œ", "ì œ ìƒê°ì—”", "ìš”ì§€ëŠ”", "ì •ë¦¬í•˜ë©´,"]
    lex = Lexicon(
        core=["ë‚˜ì˜ ì£¼ì¥", "ì§ê´€", "ì‚¬ë¡€"],
        evidentials=["ì œê°€ ë³´ê¸°ì—”", "ê²½í—˜ìƒ", "ìƒê°í•´ë³´ë©´"],
        hedges=["ì•„ë§ˆ", "ê°€ëŠ¥ì„±ì€", "ì¼ë‹¨"],
        intensifiers=["í™•ì‹¤íˆ", "ë¶„ëª…íˆ", "ê°•í•˜ê²Œ"],
        metaphors=["ë§ì€ ì§€ë„ì´ê³ , ì„¸ê³„ëŠ” ì§€í˜•ì…ë‹ˆë‹¤."],
        taboo_softeners=soft_mix,
    )
    style = StyleProfile(rhetoric_bias=0.55, justification_bias=0.65, interrogation_bias=0.60, poetic_bias=0.20)
    ops = ["define_split", "empirical_classify", "falsification", "elenchus"]
    return Philosopher(name="ì‚¬ìš©ì", era="í˜„ëŒ€", truth_vector=vec, lexicon=lex, reasoning=ReasoningOps(ops), taboo=[], style=style)
def build_grand_cast() -> List[Philosopher]:
    def L(core, evid, hed, inten, meta, soft): return Lexicon(core, evid, hed, inten, meta, soft)
    def S(rhet, just, inter, poet): return StyleProfile(rhet, just, inter, poet)
    # [FIX] Helper P now accepts concept_explanation and returns a dict for phase
    def P(name, era, vec, lex, ops, taboo, style, concept_explanation=None):
        return Philosopher(
            name=name, era=era, truth_vector=vec, lexicon=lex,
            reasoning=ReasoningOps(ops), taboo=taboo, style=style,
            concept_explanation=concept_explanation or {},
            phase={"open": 0.5, "attack": 0.5, "synthesize": 0.5} # Fixed dict
        )
    soft_mix = ["ê·¸ëŸ¬ë‚˜", "í•˜ì§€ë§Œ", "ë‹¤ë§Œ", "ê·¸ëŸ¼ì—ë„", "ë¬¼ë¡ ,", "ì¸ì •í•©ë‹ˆë‹¤ë§Œ,"]
    return [
        P("í”Œë¼í†¤","ê³ ëŒ€",{"í˜•ì´ìƒ":0.90,"ë³´í¸":0.92,"ì´ì„±":0.80}, L(["ì´ë°ì•„","ë³¸ì§ˆ"],["ìš°ì„ "],["ì•„ë§ˆë„"],["ë‹¨í˜¸íˆ"],["ê·¸ë¦¼ìë¥¼ ë³´ë©° ì§„ë¦¬ë¥¼ ë§í•  ìˆœ ì—†ìŠµë‹ˆë‹¤."],soft_mix), ["define_split","reductio","condition_censor"],[],S(0.55,0.65,0.55,0.35)),
        P("ì•„ë¦¬ìŠ¤í† í…”ë ˆìŠ¤","ê³ ëŒ€",{"ê²½í—˜":0.88,"ì´ì„±":0.75,"ë°©ë²•":0.80}, L(["ì›ì¸","ë¶„ë¥˜"],["ê´€ì°°í•˜ìë©´"],["ëŒ€ì²´ë¡œ"],["ì •í™•íˆ"],["ëŒ€ìƒì„ í•´ë¶€ëŒ€ ìœ„ì— ì˜¬ë ¤ì•¼ í•©ë‹ˆë‹¤."],soft_mix), ["empirical_classify","define_split"],[],S(0.35,0.85,0.35,0.10)),
        P("ì¹¸íŠ¸","ê·¼ëŒ€",{"ì´ì„±":0.90,"ë³´í¸":0.88,"ë„ë•":0.82}, L(["ê°€ëŠ¥ ì¡°ê±´","ë³´í¸ íƒ€ë‹¹ì„±"],["ë”°ì ¸ë³´ë©´"],["ìš°ì„ "],["ê²°ì½”"],["ê·œì¹™ ì—†ëŠ” íŒë‹¨ì€ ë‚˜ì¹¨ë°˜ ì—†ëŠ” í•­í•´ì…ë‹ˆë‹¤."],soft_mix), ["condition_censor","reductio"], [TABOOS["kant_empirical_jump"]], S(0.30,0.95,0.75,0.05)),
        P("ë‹ˆì²´","í˜„ëŒ€",{"ê¶Œë ¥":0.90,"ê°€ì¹˜":0.85,"ì§„ë¦¬":0.55}, L(["ë§ì¹˜","ìš°ìƒ","í˜"],["ë³´ë¼"],["ë•Œë•Œë¡œ"],["ê°€ì°¨ì—†ì´"],["ì§„ë¦¬ëŠ” ì•½ìì˜ ìœ„ì•ˆì´ì ê°•ìì˜ ë„êµ¬ë‹¤."],soft_mix), ["genealogy_expose","value_invert","reductio"], [TABOOS["nietzsche_universal_morals"]], S(0.90,0.45,0.55,0.75)),
        P("ì†Œí¬ë¼í…ŒìŠ¤","ê³ ëŒ€",{"ë°©ë²•":0.95,"ì£¼ì²´":0.75}, L(["ë°˜ë¬¸","ë¬´ì§€"],["ê·¸ë ‡ë‹¤ë©´"],["ì•„ë§ˆ"],["ë¶„ëª…íˆ"],["ë‚˜ëŠ” ë‚´ê°€ ëª¨ë¥¸ë‹¤ëŠ” ê²ƒì„ ì•ˆë‹¤."],soft_mix), ["elenchus","define_split"],[],S(0.45,0.60,0.95,0.05)),
        P("ë°ì¹´ë¥´íŠ¸","ê·¼ëŒ€",{"ì£¼ì²´":0.92,"ì´ì„±":0.85}, L(["ëª…ì„íŒëª…","ì˜ì‹¬"],["ë‹¨í˜¸íˆ"],["ì¼ë‹¨"],["í™•ì‹¤íˆ"],["í”ë“¤ë¦¬ëŠ” ê²ƒì€ ëª¨ë‘ ê±·ì–´ë‚´ë¼."],soft_mix), ["methodic_doubt","define_split"],[],S(0.40,0.85,0.55,0.10)),
        P("ë§ˆë¥´í¬ìŠ¤","ê·¼ëŒ€",{"ì‚¬íšŒ":0.92,"ì—­ì‚¬":0.85,"ê¶Œë ¥":0.85}, L(["ê³„ê¸‰","ìƒì‚°"],["í˜„ì‹¤ì ìœ¼ë¡œ"],["ëŒ€ê°œ"],["ë‹¨í˜¸íˆ"],["ì¤‘ìš”í•œ ê²ƒì€ í•´ì„ì´ ì•„ë‹ˆë¼ ë³€í˜ì´ë‹¤."],soft_mix), ["marx_ideology","power_knowledge"],[],S(0.70,0.55,0.55,0.20)),
        P("ë¹„íŠ¸ê²ìŠˆíƒ€ì¸","í˜„ëŒ€",{"ì–¸ì–´":0.95,"ë°©ë²•":0.85}, L(["ì–¸ì–´ê²Œì„","ê·œì¹™"],["ë³´ìë©´"],["ì•„ë§ˆë„"],["ì •í™•íˆ"],["ë§í•  ìˆ˜ ì—†ëŠ” ê²ƒì—” ì¹¨ë¬µí•˜ë¼."],soft_mix), ["language_therapy","define_split"], [TABOOS["witt_metaphysics_assert"]], S(0.25,0.85,0.55,0.10)),
        P("í—¤ê²”","ê·¼ëŒ€",{"ì—­ì‚¬":0.92,"ë°©ë²•":0.85,"ì§„ë¦¬":0.75}, L(["ë³€ì¦","ì „ê°œ"],["ë”°ë¼ê°€ë©´"],["ì¼ë‹¨"],["ê²°êµ­"],["ì§„ë¦¬ëŠ” ê³¼ì •ì´ë‹¤."],soft_mix), ["dialectic","define_split"],[],S(0.55,0.65,0.45,0.15)),
        P("ì‡¼íœí•˜ìš°ì–´","ê·¼ëŒ€",{"ì£¼ì²´":0.75,"ì¡´ì¬":0.70,"ê°€ì¹˜":0.65}, L(["ê³ í†µ","ì˜ì§€"],["ì†”ì§íˆ"],["ëŒ€ê°œ"],["ë‹¨í˜¸íˆ"],["ì‚¶ì€ ê³ í†µì˜ ì§„ìë‹¤."],soft_mix), ["pessimism_will","define_split"],[],S(0.55,0.55,0.55,0.25)),
        P("í‚¤ë¥´ì¼€ê³ ë¥´","ê·¼ëŒ€",{"ì£¼ì²´":0.90,"ê°€ì¹˜":0.80}, L(["ì‹¤ì¡´","ê²°ë‹¨"],["ë¨¼ì €"],["ì–´ì©Œë©´"],["ê²°êµ­"],["ì§„ë¦¬ëŠ” ì‚´ì•„ë‚´ëŠ” ê²ƒì´ë‹¤."],soft_mix), ["subjective_truth","existential_choice"],[],S(0.60,0.55,0.70,0.35)),
        P("í•˜ì´ë°ê±°","í˜„ëŒ€",{"ì¡´ì¬":0.92,"ì£¼ì²´":0.75}, L(["ì¡´ì¬","ë“œëŸ¬ë‚¨"],["ë¨¼ì €"],["ì–´ì©Œë©´"],["ê²°êµ­"],["ì§„ë¦¬ëŠ” ìˆ¨ê¹€ê³¼ ë“œëŸ¬ë‚¨ì˜ ì‹¸ì›€ì´ë‹¤."],soft_mix), ["being_unconceal","define_split"],[],S(0.55,0.60,0.55,0.25)),
        P("ì‚¬ë¥´íŠ¸ë¥´","í˜„ëŒ€",{"ììœ ":0.92,"ì£¼ì²´":0.88}, L(["ììœ ","ì±…ì„"],["ë‹¨í˜¸íˆ"],["ë•Œë•Œë¡œ"],["ê²°êµ­"],["ì¸ê°„ì€ ììœ ë¼ëŠ” í˜•ë²Œì„ ë°›ì•˜ë‹¤."],soft_mix), ["existential_choice","define_split"],[],S(0.70,0.55,0.55,0.30)),
        P("í‘¸ì½”","í˜„ëŒ€",{"ì‚¬íšŒ":0.90,"ê¶Œë ¥":0.90}, L(["ê·œìœ¨","ì¥ì¹˜"],["ì¶”ì í•˜ë©´"],["ëŒ€ê°œ"],["ë¶„ëª…íˆ"],["ì§„ë¦¬ëŠ” ì¥ì¹˜ ì†ì—ì„œ ìƒì‚°ëœë‹¤."],soft_mix), ["power_knowledge","genealogy_expose"], [TABOOS["foucault_truth_neutral"]], S(0.70,0.55,0.55,0.20)),
        P("ì•„ë ŒíŠ¸","í˜„ëŒ€",{"ì‚¬íšŒ":0.90,"ê°€ì¹˜":0.78}, L(["ê³µì ì„¸ê³„","í–‰ìœ„"],["ë³´ìë©´"],["ì–´ì©Œë©´"],["ë¶„ëª…íˆ"],["ì§„ë¦¬ëŠ” ì„¸ê³„ë¥¼ í•¨ê»˜ ë“œëŠ” ê²ƒì´ë‹¤."],soft_mix), ["public_world","define_split"],[],S(0.45,0.70,0.55,0.15)),
        P("í¬í¼","í˜„ëŒ€",{"ë°©ë²•":0.92,"ê²½í—˜":0.80}, L(["ë°˜ì¦","ê°€ì„¤"],["ë¨¼ì €"],["ì¼ë‹¨"],["ë¶„ëª…íˆ"],["ì§€ì‹ì€ ë°˜ë°•ì„ í†µí•´ ìë€ë‹¤."],soft_mix), ["falsification","empirical_classify"],[],S(0.35,0.80,0.55,0.05)),
        P("ë¡¤ìŠ¤","í˜„ëŒ€",{"ë„ë•":0.90,"ì‚¬íšŒ":0.85}, L(["ê³µì •","ì›ì´ˆìƒíƒœ"],["ê°€ì •í•´ë³´ë©´"],["ì¼ë‹¨"],["ë¶„ëª…íˆ"],["ê·œì¹™ì€ ì•½ìì˜ ìë¦¬ì—ì„œ ê²¬ëŒì•¼ í•œë‹¤."],soft_mix), ["original_position","condition_censor"],[],S(0.35,0.85,0.55,0.05)),
        P("ë¼ì´í”„ë‹ˆì¸ ","ê·¼ëŒ€",{"ì´ì„±":0.88,"ë³´í¸":0.85}, L(["ì¶©ë¶„ì´ìœ ","ì¡°í™”"],["ë”°ì ¸ë³´ë©´"],["ì•„ë§ˆë„"],["í•„ì—°ì ìœ¼ë¡œ"],["ì™œ ë¬´ê°€ ì•„ë‹ˆë¼ ìœ ì¸ê°€?"],soft_mix), ["condition_censor","define_split"],[],S(0.35,0.85,0.55,0.20)),
        # Eastern Trio (Fully Integrated with Precision)
        P("ì´í™©","ì¡°ì„ ",{"ë¦¬":0.95,"ì„±":0.90,"ì‹¬":0.85}, L(["ê²½","ì´ì¹˜"],["ì‚´í´ë³´ë©´"],["ì•„ë§ˆë„"],["ë‹¨í˜¸íˆ"],["ë§ˆìŒì€ ì´ì¹˜ì˜ ê·¸ë¦‡ì´ë‹¤."],soft_mix), ["define_split","condition_censor"],[],S(0.35,0.90,0.70,0.20), concept_explanation={"ë¦¬": "ë§Œë¬¼ì˜ ì´ì¹˜", "ê²½(æ•¬)": "ë§ˆìŒì˜ ì§‘ì¤‘(ê±°ê²½)"}),
        P("ì´ì´","ì¡°ì„ ",{"ê¸°":0.92,"ê²½ì„¸":0.90,"ì‹¬":0.85}, L(["ê¸°ì§ˆ","í˜„ì‹¤"],["ë‚˜ì•„ê°€ë©´"],["ëŒ€ê°œ"],["ë¶„ëª…íˆ"],["ì´ì™€ ê¸°ëŠ” ë–¨ì–´ì§ˆ ìˆ˜ ì—†ë‹¤."],soft_mix), ["empirical_classify","utilitarian"],[],S(0.40,0.88,0.60,0.15), concept_explanation={"ê¸°": "í˜„ì‹¤ì  ì—ë„ˆì§€", "ê²½ì„¸": "ì„¸ìƒì„ ë‹¤ìŠ¤ë¦¼"}),
        P("ì •ì•½ìš©","ì¡°ì„ ",{"ê²½ì„¸":0.95,"ì‹¤í•™":0.92,"ì‚¬íšŒ":0.85}, L(["ëª©ë¯¼","ì œë„"],["ì‹¤ì¦í•˜ë©´"],["ê²°êµ­"],["ë‹¨í˜¸íˆ"],["ë°±ì„±ì´ ê·¼ë³¸ì´ë‹¤."],soft_mix), ["utilitarian","marx_ideology","empirical_classify"],[],S(0.45,0.85,0.55,0.10), concept_explanation={"ì‹¤í•™": "ì‹¤ì‚¬êµ¬ì‹œ", "ëª©ë¯¼": "ë°±ì„±ì„ ê¸°ë¥´ëŠ” ë§ˆìŒ"}),
    ]
class Agora:
    def __init__(self, cast, seed=None):
        self.philos = cast
        # [CORE] Session-specific RNG
        if seed is None:
            self.rng = random.Random()
        else:
            self.rng = random.Random(seed)
        self.arb = Arbiter(len(cast))
        self.positions: Dict[str, str] = {}
    def _pick_other(self, i, r):
        n = len(self.philos)
        if n <= 1:
            return self.philos[i]
        j = (i + r) % n
        if j == i:
            j = (i + r + 1) % n
        return self.philos[j]
    async def run_async_generator(self, topic: str, rounds: int = 5, state_lock: asyncio.Lock = None, stop_event: asyncio.Event = None):
        yield f"ğŸ›ï¸ Grand Agora v52.0 (Singularity Stable Edition) | ì£¼ì œ: {topic}"
        yield f"ì°¸ì—¬ ({len(self.philos)}ëª…): {', '.join(p.name for p in self.philos[:5])}..."
        yield "-" * 50
        yield "\n[ğŸ¤ ê°œíšŒì‚¬ ë° ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì§„í–‰ ì¤‘...]"
        base_tension = 0.28
        if state_lock:
            async with state_lock:
                if "ì‚¬ìš©ì" not in self.positions:
                    self.positions["ì‚¬ìš©ì"] = f"ì €ëŠ” '{topic}'ì— ëŒ€í•´, ìµœì†Œí•œ ë°˜ë°• ê°€ëŠ¥ì„±(ê²€ì¦/ë°˜ì¦)ì´ ìˆì–´ì•¼ ì§„ë¦¬ì— ê°€ê¹ë‹¤ê³  ë´…ë‹ˆë‹¤."
        else:
            if "ì‚¬ìš©ì" not in self.positions:
                self.positions["ì‚¬ìš©ì"] = f"ì €ëŠ” '{topic}'ì— ëŒ€í•´, ìµœì†Œí•œ ë°˜ë°• ê°€ëŠ¥ì„±(ê²€ì¦/ë°˜ì¦)ì´ ìˆì–´ì•¼ ì§„ë¦¬ì— ê°€ê¹ë‹¤ê³  ë´…ë‹ˆë‹¤."
        opening_buffer: Dict[str, str] = {}
        for p in self.philos:
            if stop_event and stop_event.is_set():
                return
            if p.name == "ì‚¬ìš©ì":
                if state_lock:
                    async with state_lock:
                        s = self.positions["ì‚¬ìš©ì"]
                else:
                    s = self.positions["ì‚¬ìš©ì"]
                opening_buffer[p.name] = s
                self.arb.p_last[p.name] = s
                yield f"[ê°œíšŒì‚¬] ì‚¬ìš©ì: {s[:60]}..."
            else:
                g = build_arggraph(p, topic, "", base_tension, "open", self.rng)
                s = linearize(p, g, base_tension, self.rng)
                s = inject_topic_anchor(topic, s, p.name, self.rng, mode="opening")
                s = ensure_concept_anchor(p, s)
                opening_buffer[p.name] = s
                self.arb.p_last[p.name] = s
                if self.rng.random() < 0.25:
                    yield f"[ê°œíšŒì‚¬] {p.name}: {s[:60]}..."
            await asyncio.sleep(0.01)
        if state_lock:
            async with state_lock:
                self.positions.update(opening_buffer)
        else:
            self.positions.update(opening_buffer)
        for r in range(1, rounds + 1):
            if stop_event and stop_event.is_set():
                return
            yield f"\nğŸŒ€ Round {r}"
            yield "-" * 50
            for i, me in enumerate(self.philos):
                if stop_event and stop_event.is_set():
                    return
                if me.name == "ì‚¬ìš©ì":
                    if state_lock:
                        async with state_lock:
                            s = self.positions.get("ì‚¬ìš©ì", "").strip()
                    else:
                        s = self.positions.get("ì‚¬ìš©ì", "").strip()
                    if not s:
                        yield "\nğŸ—£ï¸ ì‚¬ìš©ì: (ì´ë²ˆ í„´ì€ ë°œì–¸ ì—†ìŒ)"
                        continue
                    verdict = self.arb.judge(s, me.name)
                    hud = f" ğŸ“Š [Mode:USER->USER | Fric:0.00] (T:{verdict.tension:.2f} C:{verdict.coherence:.2f} N:{verdict.novelty:.2f})"
                    yield f"\nğŸ—£ï¸ ì‚¬ìš©ì:\n\"{s}\""
                    yield hud
                    self.arb.adapt(self.philos, verdict)
                    await asyncio.sleep(0.1)
                    continue
                other = self._pick_other(i, r)
                if state_lock:
                    async with state_lock:
                        other_claim = self.positions.get(other.name, "")
                else:
                    other_claim = self.positions.get(other.name, "")
                dist = 1.0 - cosine_sim(me.truth_vector, other.truth_vector)
                if not other_claim.strip():
                    friction = clamp(0.55 * dist + 0.05, 0.0, 1.0)
                else:
                    other_cg = concept_graph_score(me.name, other_claim)
                    taboo_s, _ = taboo_score(me.taboo, other_claim)
                    friction = clamp(0.55 * dist + 0.25 * taboo_s + 0.20 * (1.0 - other_cg), 0.0, 1.0)
                if friction > 0.60:
                    mode = "attack"
                elif friction > 0.35:
                    mode = "open"
                else:
                    mode = "synthesize"
                tension = clamp(0.30 + 0.70 * friction, 0.0, 1.0)
                g = build_arggraph(me, topic, other_claim, tension, mode, self.rng)
                s = linearize(me, g, tension, self.rng)
                ts, hits = taboo_score(me.taboo, s)
                if ts > 0.55:
                    s = apply_taboo_repairs(me, s, hits, topic, self.rng)
                s = inject_topic_anchor(topic, s, me.name, self.rng, mode="normal")
                s = ensure_concept_anchor(me, s)
                n0 = self.arb.novelty_check(s, me.name)
                re_roll_msg = ""
                if n0 < RE_ROLL_THRESHOLD and me.style.rhetoric_bias > RHETORIC_THRESHOLD:
                    cands = {"attack", "open", "synthesize"} - {mode}
                    new_mode = self.rng.choice(list(cands))
                    mode_display = f"{mode.upper()}->{new_mode.upper()}"
                    mode = new_mode
                    tension_boost = clamp(tension + 0.25, 0.0, 1.0)
                    g2 = build_arggraph(me, topic, other_claim, tension_boost, mode, self.rng, entropy_boost=0.3)
                    s2 = linearize(me, g2, tension_boost, self.rng)
                    ts2, hits2 = taboo_score(me.taboo, s2)
                    if ts2 > 0.55:
                        s2 = apply_taboo_repairs(me, s2, hits2, topic, self.rng)
                   
                    s2 = inject_topic_anchor(topic, s2, me.name, self.rng, mode="reroll")
                    s = ensure_concept_anchor(me, s2)
                    re_roll_msg = f" ğŸ”„ (Re-roll via {mode_display})"
                else:
                    mode_display = f"{mode.upper()}->{mode.upper()}"
                verdict = self.arb.judge(s, me.name)
                note_str = f" {verdict.note}" if verdict.note else ""
                hud = f" ğŸ“Š [Mode:{mode_display:<15} | Fric:{friction:.2f}] (T:{verdict.tension:.2f} C:{verdict.coherence:.2f} N:{verdict.novelty:.2f}){note_str}"
                if re_roll_msg:
                    yield re_roll_msg
                yield f"\nğŸ—£ï¸ {me.name} â†’ {other.name}:\n\"{s}\""
                yield f"{hud} => {verdict.status}" if verdict.status != "CONTINUE" else hud
                self.arb.adapt(self.philos, verdict)
                if state_lock:
                    async with state_lock:
                        self.positions[me.name] = s
                else:
                    self.positions[me.name] = s
                if verdict.status == "MELTDOWN":
                    yield "\nğŸ›‘ [SYSTEM] ì—”íŠ¸ë¡œí”¼ ì„ê³„ì  ì´ˆê³¼. íŒŒêµ­(MELTDOWN)ìœ¼ë¡œ ì¸í•´ í† ë¡  ì¤‘ë‹¨."
                    return
                if verdict.status == "CONSENSUS":
                    yield "\nâœ… [SYSTEM] ê³µëª…(Resonance) ë°œìƒ. í•©ì˜ ë„ë‹¬."
                    return
                await asyncio.sleep(0.1)
# ============================================================
# [SECTION 2] The Server & UI (Singularity Stable Edition)
# ============================================================
app = FastAPI()
# [SEC] Helper Logic for B64URL
def b64u_enc(b: bytes) -> str:
    return base64.urlsafe_b64encode(b).decode().rstrip("=")
def b64u_dec(s: str) -> bytes:
    pad = "=" * (-len(s) % 4)
    return base64.urlsafe_b64decode(s + pad)
# [SEC] Stateless HMAC Ticket with JTI & IAT (Replay Resistant)
USED_JTIS: Dict[str, float] = {}
JTI_LOCK = asyncio.Lock()
def sign_ticket(ip: str, iat: float, exp: float) -> str:
    # JTI = Unique Nonce
    jti = secrets.token_hex(8)
    # Payload: "IP|IAT|EXP|JTI"
    payload = f"{ip}|{iat}|{exp}|{jti}".encode()
    signature = hmac.new(MASTER_SECRET.encode(), payload, hashlib.sha256).digest()
    return f"{b64u_enc(payload)}.{b64u_enc(signature)}"
async def verify_ticket(ticket: str, client_ip: str) -> bool:
    try:
        parts = ticket.split(".")
        if len(parts) != 2: return False
       
        payload_b64, sig_b64 = parts
        payload = b64u_dec(payload_b64)
        signature = b64u_dec(sig_b64)
       
        # Verify Signature (Constant Time)
        expected_sig = hmac.new(MASTER_SECRET.encode(), payload, hashlib.sha256).digest()
        if not secrets.compare_digest(signature, expected_sig):
            return False
           
        # Verify Content
        ip, iat_str, exp_str, jti = payload.decode().split("|")
       
        # [CONF] Optional IP Binding Check
        if BIND_TICKET_IP and ip != client_ip:
            return False
       
        now = time.time()
        iat = float(iat_str)
        exp = float(exp_str)
       
        if now > exp: return False
        if now < iat - 5.0: return False
       
        # [SEC] Strict Usage Window Enforced
        if now - iat > TICKET_USAGE_WINDOW: return False
        async with JTI_LOCK:
            # [OPS] Sorted GC (Earliest Expiry First)
            # 1. Clean expired keys first
            expired = [k for k, v in USED_JTIS.items() if v < now]
            for k in expired: del USED_JTIS[k]
            # 2. Hard Cap Check with Sorted Eviction
            if len(USED_JTIS) > JTI_MAX_TRACKING:
                 # Sort by expiry (asc) to evict soonest-to-expire/oldest
                 # This is O(N log N) but safer than random eviction
                 sorted_jtis = sorted(USED_JTIS.items(), key=lambda item: item[1])
                 overflow = len(USED_JTIS) - JTI_MAX_TRACKING
                 # Evict overflow amount
                 for i in range(overflow):
                     del USED_JTIS[sorted_jtis[i][0]]
            # Replay Check
            if jti in USED_JTIS: return False
            USED_JTIS[jti] = exp
           
        return True
    except Exception:
        return False
# [CONCURRENCY] Global Lock for Stats (Defined)
GLOBAL_LOCK = asyncio.Lock()
TICKET_RATE_LIMITER = defaultdict(float)
WS_MSG_RATE_LIMITER = defaultdict(float)
IP_LAST_SEEN = defaultdict(float)
IP_ACTIVE_CONNS = defaultdict(int)
LAST_GC_TIME = 0.0
# [NET] Unified IP Extraction Helper
def is_trusted_proxy(ip_str: str) -> bool:
    try:
        ip = ipaddress.ip_address(ip_str)
        return any(ip in net for net in TRUSTED_NETWORKS)
    except ValueError:
        return False
def get_real_client_ip(request_or_ws: Union[Request, WebSocket]) -> str:
    if isinstance(request_or_ws, Request):
        peer_ip = request_or_ws.client.host if request_or_ws.client else "unknown"
    else:
        peer_ip = request_or_ws.client.host if request_or_ws.client else "unknown"
       
    forwarded = request_or_ws.headers.get("x-forwarded-for")
   
    if forwarded and is_trusted_proxy(peer_ip):
        try:
            candidate = forwarded.split(",")[0].strip()
            ipaddress.ip_address(candidate)
            return candidate
        except ValueError:
            pass
           
    return peer_ip
# [SEC] Unified Origin Check with Host Fallback
def check_origin(headers) -> bool:
    origin = headers.get("origin")
    host = headers.get("host")
   
    # [SEC] Hardened Dev Mode Logic
    if not DEV_MODE:
        # Prod: Strict Origin Required (No Host Fallback)
        if not origin: return False
        try:
            o = urlparse(origin)
            normalized = f"{o.scheme}://{o.netloc}"
            return normalized in ALLOWED_ORIGINS
        except:
            return False
           
    # Dev Mode: Permissive but sane
    if origin:
        if origin == "null": return True
        try:
            o = urlparse(origin)
            normalized = f"{o.scheme}://{o.netloc}"
            return normalized in ALLOWED_ORIGINS
        except:
            pass
   
    # Dev Mode: Fallback to Host if Origin missing (e.g. tools)
    if host:
         try:
             return any(host == urlparse(allowed).netloc for allowed in ALLOWED_ORIGINS)
         except:
             pass
    return False # Default Deny
@app.get("/ticket")
async def issue_ticket_endpoint(request: Request):
    # [SEC] Ticket Origin Check
    if not check_origin(request.headers):
         # Double check for Host if Origin missing
         host = request.headers.get("host")
         allowed = False
         if host:
             for ao in ALLOWED_ORIGINS:
                 if host == urlparse(ao).netloc:
                     allowed = True
                     break
         if not allowed:
            raise HTTPException(status_code=403, detail="Origin/Host not allowed")
    client_ip = get_real_client_ip(request)
   
    now = time.time()
    async with GLOBAL_LOCK:
        if now - TICKET_RATE_LIMITER[client_ip] < 1.0:
            raise HTTPException(status_code=429, detail="Slow down")
        TICKET_RATE_LIMITER[client_ip] = now
   
    expiry = now + TICKET_TTL
    # [SEC] Sign with IAT for replay window enforcement
    ticket = sign_ticket(client_ip, now, expiry)
    return {"ticket": ticket}
html = """
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Agora Interactive (Singularity Stable)</title>
    <style>
        body { font-family: 'Courier New', monospace; background: #0d1117; color: #c9d1d9; margin: 0; padding: 20px; display: flex; flex-direction: column; height: 95vh; }
        h1 { color: #58a6ff; text-align: center; margin-bottom: 10px; font-size: 1.5rem; }
        #chat-container { flex: 1; border: 1px solid #30363d; border-radius: 6px; padding: 15px; overflow-y: auto; background: #161b22; margin-bottom: 15px; box-shadow: inset 0 0 10px #000; }
        .message { margin-bottom: 8px; line-height: 1.4; border-bottom: 1px solid #21262d; padding-bottom: 4px; white-space: pre-wrap; }
        .hud { color: #8b949e; font-size: 0.85em; }
        .system { color: #f0883e; font-weight: bold; }
        .speaker { color: #79c0ff; font-weight: bold; }
        .reroll { color: #d2a8ff; font-style: italic; }
        #input-area { display: flex; gap: 10px; flex-direction: column; }
        .input-row { display: flex; gap: 10px; }
        input { flex: 1; padding: 10px; border-radius: 6px; border: 1px solid #30363d; background: #0d1117; color: #c9d1d9; font-family: inherit; }
        button { padding: 10px 20px; border-radius: 6px; border: none; background: #238636; color: white; cursor: pointer; font-weight: bold; font-family: inherit; }
        button#stopBtn { background: #da3633; }
        button:disabled { background: #484f58; cursor: not-allowed; }
        button:hover:not(:disabled) { opacity: 0.9; }
        input:focus { outline: 2px solid #58a6ff; }
        ::-webkit-scrollbar { width: 10px; }
        ::-webkit-scrollbar-track { background: #0d1117; }
        ::-webkit-scrollbar-thumb { background: #30363d; border-radius: 5px; }
        ::-webkit-scrollbar-thumb:hover { background: #58a6ff; }
    </style>
</head>
<body>
    <h1>ğŸ›ï¸ Grand Philosophical Agora (Singularity Stable)</h1>
    <div id="chat-container">
        <div class="message system">SYSTEM: ì—°ê²° ì¤€ë¹„ ì¤‘... í‹°ì¼“ ë°œê¸‰ ìš”ì²­...</div>
    </div>
    <div id="input-area">
        <div class="input-row">
            <input type="text" id="topicInput" placeholder="ì£¼ì œ: (ì˜ˆ: ì •ì˜ë€ ë¬´ì—‡ì¸ê°€?)" />
        </div>
        <div class="input-row">
            <input type="text" id="userClaimInput" placeholder="ë‚˜ì˜ ì£¼ì¥ / ê°œì… (Enterë¡œ ì „ì†¡)" />
            <button id="startBtn" onclick="sendAction('start')" disabled>í† ë¡  ì‹œì‘</button>
            <button id="stopBtn" onclick="sendAction('stop')" disabled>ì¤‘ë‹¨</button>
        </div>
    </div>
    <script>
        let ws;
        const chat = document.getElementById("chat-container");
        const topicInput = document.getElementById("topicInput");
        const claimInput = document.getElementById("userClaimInput");
        const startBtn = document.getElementById("startBtn");
        const stopBtn = document.getElementById("stopBtn");
        async function connectWS() {
            try {
                const res = await fetch("/ticket");
                if (!res.ok) {
                    if (res.status === 429) throw new Error("Too many requests");
                    if (res.status === 403) throw new Error("Access Denied (Origin/Host)");
                    throw new Error("Ticket failed: " + res.status);
                }
                const data = await res.json();
                const ticket = data.ticket;
                const scheme = (location.protocol === "https:") ? "wss://" : "ws://";
                ws = new WebSocket(scheme + window.location.host + "/ws?ticket=" + ticket);
                ws.onopen = function() {
                    const msg = document.createElement("div");
                    msg.className = "message system";
                    msg.innerText = "SYSTEM: ì„œë²„ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤ (Secure).";
                    chat.appendChild(msg);
                    startBtn.disabled = false;
                    stopBtn.disabled = true;
                    startBtn.innerText = "í† ë¡  ì‹œì‘";
                };
                ws.onmessage = function(event) {
                    const msg = document.createElement("div");
                    msg.className = "message";
                    let text = event.data;
                    if (text.includes("ğŸ“Š")) msg.className += " hud";
                    else if (text.includes("SYSTEM") || text.includes("ê°œíšŒì‚¬")) msg.className += " system";
                    else if (text.includes("ğŸ”„")) msg.className += " reroll";
                    else if (text.includes("ğŸ—£ï¸")) msg.className += " speaker";
                    msg.innerText = text;
                    chat.appendChild(msg);
                    chat.scrollTop = chat.scrollHeight;
                    if (text.includes("í† ë¡  ì¤‘ë‹¨") || text.includes("í•©ì˜ ë„ë‹¬") || text.includes("í† ë¡ ì´ ì¢…ë£Œ") || text.includes("í† ë¡ ì„ ì¢…ë£Œí•©ë‹ˆë‹¤")) {
                        startBtn.disabled = false;
                        stopBtn.disabled = true;
                        startBtn.innerText = "ìƒˆ í† ë¡  ì‹œì‘";
                    }
                };
                ws.onclose = function(event) {
                    const msg = document.createElement("div");
                    msg.className = "message system";
                    let reason = "ì—°ê²°ì´ ëŠì–´ì¡ŒìŠµë‹ˆë‹¤.";
                    if (event.code === 1008) reason = "ì ‘ê·¼ ê±°ë¶€ (Auth/Origin/Busy)";
                    else if (event.code === 1011) reason = "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜";
                   
                    msg.innerText = `SYSTEM: ${reason} ì¬ì—°ê²° ì‹œë„ ì¤‘...`;
                    chat.appendChild(msg);
                    setTimeout(connectWS, 2000);
                };
            } catch (e) {
                console.error(e);
                const msg = document.createElement("div");
                msg.className = "message system";
                msg.innerText = `SYSTEM: ì—°ê²° ì‹¤íŒ¨ (${e.message}). ì¬ì‹œë„ ì¤‘...`;
                chat.appendChild(msg);
                setTimeout(connectWS, 3000);
            }
        }
        connectWS();
        function sendAction(type) {
            if (!ws || ws.readyState !== WebSocket.OPEN) return;
            if (type === 'start') {
                const topic = topicInput.value.trim();
                const userClaim = claimInput.value.trim();
                if (!topic) { alert("ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."); return; }
                startBtn.disabled = true;
                stopBtn.disabled = false;
                startBtn.innerText = "ì§„í–‰ ì¤‘...";
                chat.innerHTML = "";
                ws.send(JSON.stringify({ type: 'start', topic: topic, user_claim: userClaim }));
                claimInput.value = "";
                claimInput.placeholder = "í† ë¡  ì¤‘ ì–¸ì œë“ ì§€ ê°œì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤...";
            }
            else if (type === 'update') {
                if (!startBtn.disabled) return;
                const userClaim = claimInput.value.trim();
                if (!userClaim) return;
                ws.send(JSON.stringify({ type: 'update', text: userClaim }));
                claimInput.value = "";
            }
            else if (type === 'stop') {
                stopBtn.disabled = true;
                startBtn.disabled = false;
                startBtn.innerText = "ìƒˆ í† ë¡  ì‹œì‘";
                ws.send(JSON.stringify({ type: 'stop' }));
            }
        }
        claimInput.addEventListener("keydown", (e) => {
            if (e.key === "Enter" && !e.isComposing) {
                e.preventDefault();
                if (!startBtn.disabled) sendAction('start');
                else sendAction('update');
            }
        });
    </script>
</body>
</html>
"""
@app.get("/")
async def get():
    return HTMLResponse(html)
# [SEC] Concurrent Connection Limit
CONNECTION_SEMAPHORE = asyncio.Semaphore(10)
def ip_gc(now: float):
    global LAST_GC_TIME
    if now - LAST_GC_TIME < GC_INTERVAL:
        return
   
    LAST_GC_TIME = now
   
    keys_to_del = [ip for ip, ts in IP_LAST_SEEN.items() if now - ts > IP_TTL]
    for ip in keys_to_del:
        IP_LAST_SEEN.pop(ip, None)
        TICKET_RATE_LIMITER.pop(ip, None)
        WS_MSG_RATE_LIMITER.pop(ip, None)
       
    # [OPS] Bulk Eviction
    if len(IP_LAST_SEEN) > IP_MAX_TRACKING:
        overflow_count = len(IP_LAST_SEEN) - IP_MAX_TRACKING + 100
        all_keys = list(IP_LAST_SEEN.keys())
        victims = random.sample(all_keys, min(len(all_keys), overflow_count))
        for ip in victims:
            IP_LAST_SEEN.pop(ip, None)
            TICKET_RATE_LIMITER.pop(ip, None)
            WS_MSG_RATE_LIMITER.pop(ip, None)
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    # [SEC] Strict Origin Check
    if not check_origin(websocket.headers):
         await websocket.close(code=1008)
         return
    # [NET] Unified IP Extraction
    client_ip = get_real_client_ip(websocket)
    # [SEC] Verify Stateless Ticket (Strict IP match + IAT + JTI)
    try:
        # [REF] Use native Starlette query parsing
        qs = parse_qs(websocket.url.query)
        ticket = qs.get("ticket", [""])[0]
       
        # [SEC] Verify with Async for JTI Lock
        if not await verify_ticket(ticket, client_ip):
             await websocket.close(code=1008)
             return
    except:
        await websocket.close(code=1008)
        return
    # [FIX] Relaxed Atomic Semaphore
    sem_acquired = False
    try:
        await asyncio.wait_for(CONNECTION_SEMAPHORE.acquire(), timeout=1.0)
        sem_acquired = True
    except asyncio.TimeoutError:
        await websocket.close(code=1008, reason="Server busy")
        return
    ip_counted = False
   
    try:
        await websocket.accept()
        # [SEC] Per-IP Connection Limit
        async with GLOBAL_LOCK:
            if IP_ACTIVE_CONNS[client_ip] >= MAX_CONCURRENT_PER_IP:
                 await websocket.close(code=1008, reason="Too many connections")
                 return
            IP_ACTIVE_CONNS[client_ip] += 1
            ip_counted = True
        agora_instance: Optional[Agora] = None
        simulation_task: Optional[asyncio.Task] = None
        sender_task: Optional[asyncio.Task] = None
       
        # [CONCURRENCY] Safe Queue Replacement Strategy
        msg_queue = asyncio.Queue(maxsize=50)
        state_lock = asyncio.Lock()
        stop_event = asyncio.Event()
       
        # [OPS] Sender Loop with Sentinel Check
        async def sender_loop():
            try:
                while True:
                    msg = await msg_queue.get()
                    if msg is None: # Sentinel
                        msg_queue.task_done()
                        break
                    try:
                        await websocket.send_text(msg)
                    finally:
                        msg_queue.task_done()
            except asyncio.CancelledError:
                pass
            except Exception as e:
                stop_event.set()
                try:
                    await websocket.close(code=1011)
                except:
                    pass
        sender_task = asyncio.create_task(sender_loop())
        async def safe_send_queue(msg: str, critical: bool = False):
            try:
                msg_queue.put_nowait(msg)
            except asyncio.QueueFull:
                if not critical:
                    return
                try:
                    _ = msg_queue.get_nowait()
                    msg_queue.task_done()
                except asyncio.QueueEmpty:
                    pass
                try:
                    msg_queue.put_nowait(msg)
                except asyncio.QueueFull:
                    pass
        async def cancel_task_safely():
            nonlocal simulation_task
            if simulation_task and not simulation_task.done():
                simulation_task.cancel()
                try:
                    await simulation_task
                except asyncio.CancelledError:
                    pass
            simulation_task = None
        try:
            while True:
                try:
                    data = await websocket.receive_text()
                except WebSocketDisconnect:
                    raise
                except Exception:
                    break
                now = time.time()
               
                # [OPS] Thread-Safe Stats Update (Optimized Lock Scope)
                async with GLOBAL_LOCK:
                    ip_gc(now)
                    IP_LAST_SEEN[client_ip] = now
                    # [OPS] Separate WS Rate Limiter with Warning
                    if now - WS_MSG_RATE_LIMITER[client_ip] < 0.05:
                        await safe_send_queue("âš ï¸ ë©”ì‹œì§€ê°€ ë„ˆë¬´ ë¹ ë¦…ë‹ˆë‹¤.", critical=False)
                        continue
                    WS_MSG_RATE_LIMITER[client_ip] = now
                if len(data) > 10000:
                    await safe_send_queue("\nâš ï¸ [SYSTEM] ì…ë ¥ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤.", critical=True)
                    continue
                try:
                    payload = json.loads(data)
                    action_type = payload.get("type", "start")
                except:
                    continue
                if action_type == "start":
                    # [OPS] Start Rate Limiter (Session Flooding Protection)
                    async with GLOBAL_LOCK:
                        if now - START_RATE_LIMITER[client_ip] < 1.0:
                             await safe_send_queue("âš ï¸ ë„ˆë¬´ ìì£¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", critical=True)
                             continue
                        START_RATE_LIMITER[client_ip] = now
                    stop_event.set()
                    await cancel_task_safely()
                    # [CONCURRENCY] New Queue/Task for New Session (Safe Reset)
                    # No manual drain needed as we replace the queue context if we were re-architecting fully,
                    # but here we reuse the connection-scoped queue. Drain is safer.
                    while not msg_queue.empty():
                        try:
                            msg_queue.get_nowait()
                            msg_queue.task_done()
                        except:
                            break
                           
                    stop_event.clear()
                    topic = payload.get("topic", "ì§„ë¦¬")[:100]
                    user_claim = payload.get("user_claim", "") or ""
                    user_claim = user_claim[:500]
                    # [LOGIC] User Philosopher Injection
                    cast = build_grand_cast()
                    user_p = build_user_philosopher(user_claim)
                    # Insert user at the front
                    cast.insert(0, user_p)
                   
                    topic_seed = int(hashlib.sha256(topic.encode('utf-8')).hexdigest(), 16)
                    agora_instance = Agora(cast, seed=topic_seed)
                    async with state_lock:
                        agora_instance.positions["ì‚¬ìš©ì"] = (
                            user_claim if user_claim else f"ì €ëŠ” '{topic}'ì— ëŒ€í•´, ìµœì†Œí•œ ë°˜ë°• ê°€ëŠ¥ì„±(ê²€ì¦/ë°˜ì¦)ì´ ìˆì–´ì•¼ ì§„ë¦¬ì— ê°€ê¹ë‹¤ê³  ë´…ë‹ˆë‹¤."
                        )
                    async def run_sim():
                        nonlocal agora_instance
                        try:
                            async for line in agora_instance.run_async_generator(topic=topic, rounds=MAX_ROUNDS_PER_SESSION, state_lock=state_lock, stop_event=stop_event):
                                if stop_event.is_set():
                                    break
                                await safe_send_queue(line)
                           
                            if not stop_event.is_set():
                                await safe_send_queue("\nğŸ [SYSTEM] í† ë¡ ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", critical=True)
          except WebSocketDisconnect:
            stop_event.set()
            await cancel_task_safely()
            print("Client disconnected cleanly")
        except Exception as e:
            stop_event.set()
            await cancel_task_safely()
            print(f"Main Loop Error: {e}")
        finally:
            # [OPS] Sentinel Shutdown
            if sender_task:
                try:
                    msg_queue.put_nowait(None) # Signal exit
                    await asyncio.wait_for(sender_task, timeout=1.0)
                except:
                    sender_task.cancel()
           
            # [FIX] Flag-Guarded Decrement with Global Lock
            if ip_counted:
                async with GLOBAL_LOCK:
                    IP_ACTIVE_CONNS[client_ip] -= 1
                    if IP_ACTIVE_CONNS[client_ip] <= 0:
                        del IP_ACTIVE_CONNS[client_ip]
    finally:
        # [FIX] Flag-Guarded Release
        if sem_acquired:
            CONNECTION_SEMAPHORE.release()
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
