# ğŸ§  Resonetics Engine: Performance Edition (v6.1)

[![License: AGPL-3.0](https://img.shields.io/badge/License-AGPL_3.0-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)
[![Python](https://img.shields.io/badge/Python-3.9%2B-green)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109-teal)](https://fastapi.tiangolo.com/)
[![Status](https://img.shields.io/badge/Status-Production_Ready-success)](https://github.com/)

> **"Logic is not just semantics; it is a topological structure."**

**Resonetics Engine**ì€ ìµœì‹  **ìœ„ìƒìˆ˜í•™ì  ë°ì´í„° ë¶„ì„(TDA)**ê³¼ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(SBERT)**ì„ ê²°í•©í•œ ê³ ì„±ëŠ¥ ë…¼ë¦¬ ì¶”ë¡  ê²€ì¦ ì—”ì§„ì…ë‹ˆë‹¤. ë‹¨ìˆœí•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ë„˜ì–´, ë¬¸ì¥ ê°„ì˜ **êµ¬ì¡°ì  ì—°ê²°ì„±(Structural Connectivity)**ì„ ìˆ˜í•™ì ìœ¼ë¡œ ì¦ëª…í•©ë‹ˆë‹¤.

v6.1ì€ **GPU ê°€ì†**, **Rust ê¸°ë°˜ ì§ë ¬í™”(orjson)**, **í•˜ì´ë¸Œë¦¬ë“œ TDA ì•„í‚¤í…ì²˜**ë¥¼ í†µí•´ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì¶”ë¡ ì´ ê°€ëŠ¥í•˜ë„ë¡ ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤.

---

## ğŸš€ Key Features (v6.1)

### âš¡ Extreme Performance
* **GPU Accelerated SBERT:** ë°°ì¹˜(Batch) ì²˜ë¦¬ë¥¼ í†µí•´ ì„ë² ë”© ì†ë„ë¥¼ **10ë°° ì´ìƒ** ê°€ì†í™”í–ˆìŠµë‹ˆë‹¤.
* **Rust Serialization:** `orjson`ì„ ë„ì…í•˜ì—¬ JSON ì§ë ¬í™” ì˜¤ë²„í—¤ë“œë¥¼ ì œê±°í–ˆìŠµë‹ˆë‹¤.
* **Hybrid TDA Architecture:** ìºì‹œ(Cache) â†’ ë¹„ë™ê¸° TDA(Async) â†’ í´ë°±(Fallback) 3ë‹¨ê³„ ì „ëµìœ¼ë¡œ ì†ë„ì™€ ì •í™•ë„ë¥¼ ëª¨ë‘ ì¡ì•˜ìŠµë‹ˆë‹¤.

### ğŸ§¬ Topological Reasoning (ìœ„ìƒìˆ˜í•™ì  ì¶”ë¡ )
* **Persistent Homology:** ë°ì´í„°ì˜ 'êµ¬ë©(Loop)'ì„ ì°¾ì•„ ë…¼ë¦¬ì  ë¹„ì•½ì´ë‚˜ ë‹¨ì ˆì„ ê°ì§€í•©ë‹ˆë‹¤.
* **Time-Delay Embedding:** 1ì°¨ì› í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ ê³ ì°¨ì› í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¡œ ë³€í™˜í•˜ì—¬ êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
* **Confidence Score:** ì¶”ë¡ ì˜ ì‹ ë¢°ë„ë¥¼ `Method` (TDA/Fallback)ì™€ `Coherence`ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì¹˜í™”í•©ë‹ˆë‹¤.

### ğŸ›¡ï¸ Production Ready
* **Memory Safety:** `SizedLRUCache`ë¥¼ í†µí•´ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜(OOM)ë¥¼ ì›ì²œ ì°¨ë‹¨í•©ë‹ˆë‹¤.
* **Observability:** Prometheus ë©”íŠ¸ë¦­(`INFERENCE_REQUESTS`, `TDA_CALC_TIME`)ì´ ë‚´ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
* **Streaming API:** SSE(Server-Sent Events)ë¥¼ í†µí•´ ì¶”ë¡  ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¤‘ê³„í•©ë‹ˆë‹¤.

---

## ğŸ› ï¸ Quick Start

### 1. Prerequisites
* Python 3.9+
* CUDA capable GPU (Recommended) or Multi-core CPU

### 2. Installation
```bash
# Clone the repository
git clone [https://github.com/red1239109-cmd/resonetics-engine.git](https://github.com/red1239109-cmd/resonetics-engine.git)
cd resonetics-engine

# Install dependencies
pip install torch sentence-transformers fastapi uvicorn ripser gudhi orjson prometheus_client

3. Running the Server
Option A: With GPU (Recommended)

# Workers=1 to avoid VRAM duplication. Internal process pool handles CPU tasks.
uvicorn resonetics_engine_v6_1:app --host 0.0.0.0 --port 8000 --workers 1

Option B: CPU Only

# Scale workers to utilize CPU cores
uvicorn resonetics_engine_v6_1:app --host 0.0.0.0 --port 8000 --workers 4

Usage Example (Curl)

curl -N -X POST http://localhost:8000/infer_stream \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Is AI dangerous?",
    "premises": [
      "AI systems learn patterns from massive data.",
      "Human data inherently contains historical biases.",
      "Learning from biased data transfers bias to the model.",
      "Biased models can make unfair decisions in society.",
      "Therefore, AI poses a potential danger."
    ]
  }'

  Response (Stream):

  {"premise": "AI systems...", "conclusion": "Human data...", "coherence": 0.92, "method": "TDA", "confidence": 0.92}
{"premise": "Human data...", "conclusion": "Learning from...", "coherence": 0.88, "method": "CACHE", "confidence": 0.88}
...
